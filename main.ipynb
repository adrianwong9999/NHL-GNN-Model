{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87699c5e-67f9-4b52-b92f-eb37607b727a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('data/NHL.csv', header=None)\n",
    "dataset.columns = ['year', 'league', 'time', 'home_team', 'away_team', 'home_score', 'away_score', 'difference_score','result', 'country', 'home_shots', 'away_shots','home_hits','away_hits']\n",
    "dataset = dataset.drop(columns = ['year', 'league', 'country'])\n",
    "dataset.away_team.unique()\n",
    "dataset.to_csv('data/NHL_with_headers.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('data/NHL_with_headers.csv')\n",
    "df['time'] = pd.to_datetime(df['time'], format='%d-%m-%y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfdb2bfc-5000-4c8c-8ce3-5482f63d458f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.962006092071533\n",
      "Epoch 2, Loss: 4.337645053863525\n",
      "Epoch 3, Loss: 4.161351680755615\n",
      "Epoch 4, Loss: 3.0918431282043457\n",
      "Epoch 5, Loss: 3.0166945457458496\n",
      "Epoch 6, Loss: 2.6225526332855225\n",
      "Epoch 7, Loss: 2.011362314224243\n",
      "Epoch 8, Loss: 1.855964183807373\n",
      "Epoch 9, Loss: 1.7712132930755615\n",
      "Epoch 10, Loss: 1.50192129611969\n",
      "Epoch 11, Loss: 1.349860668182373\n",
      "Epoch 12, Loss: 1.3059483766555786\n",
      "Epoch 13, Loss: 1.1912384033203125\n",
      "Epoch 14, Loss: 1.1521503925323486\n",
      "Epoch 15, Loss: 1.1336616277694702\n",
      "Epoch 16, Loss: 1.0912500619888306\n",
      "Epoch 17, Loss: 1.0882285833358765\n",
      "Epoch 18, Loss: 1.0828911066055298\n",
      "Epoch 19, Loss: 1.07660710811615\n",
      "Epoch 20, Loss: 1.0616663694381714\n",
      "Epoch 21, Loss: 1.0712110996246338\n",
      "Epoch 22, Loss: 1.068063735961914\n",
      "Epoch 23, Loss: 1.0644915103912354\n",
      "Epoch 24, Loss: 1.0820668935775757\n",
      "Epoch 25, Loss: 1.0645034313201904\n",
      "Epoch 26, Loss: 1.0664615631103516\n",
      "Epoch 27, Loss: 1.0702685117721558\n",
      "Epoch 28, Loss: 1.062282919883728\n",
      "Epoch 29, Loss: 1.0531803369522095\n",
      "Epoch 30, Loss: 1.0632474422454834\n",
      "Epoch 31, Loss: 1.056937575340271\n",
      "Epoch 32, Loss: 1.0600900650024414\n",
      "Epoch 33, Loss: 1.0626583099365234\n",
      "Epoch 34, Loss: 1.0575971603393555\n",
      "Epoch 35, Loss: 1.056908130645752\n",
      "Epoch 36, Loss: 1.0645188093185425\n",
      "Epoch 37, Loss: 1.0638718605041504\n",
      "Epoch 38, Loss: 1.051241159439087\n",
      "Epoch 39, Loss: 1.0601998567581177\n",
      "Epoch 40, Loss: 1.05181884765625\n",
      "Epoch 41, Loss: 1.0602401494979858\n",
      "Epoch 42, Loss: 1.0571764707565308\n",
      "Epoch 43, Loss: 1.051450490951538\n",
      "Epoch 44, Loss: 1.050010323524475\n",
      "Epoch 45, Loss: 1.0520367622375488\n",
      "Epoch 46, Loss: 1.058608055114746\n",
      "Epoch 47, Loss: 1.0511481761932373\n",
      "Epoch 48, Loss: 1.0565739870071411\n",
      "Epoch 49, Loss: 1.0533447265625\n",
      "Epoch 50, Loss: 1.0564647912979126\n",
      "Epoch 51, Loss: 1.0505805015563965\n",
      "Epoch 52, Loss: 1.0535824298858643\n",
      "Epoch 53, Loss: 1.0573341846466064\n",
      "Epoch 54, Loss: 1.0574307441711426\n",
      "Epoch 55, Loss: 1.0513519048690796\n",
      "Epoch 56, Loss: 1.0548980236053467\n",
      "Epoch 57, Loss: 1.044535756111145\n",
      "Epoch 58, Loss: 1.0551600456237793\n",
      "Epoch 59, Loss: 1.0558520555496216\n",
      "Epoch 60, Loss: 1.0445716381072998\n",
      "Epoch 61, Loss: 1.048903465270996\n",
      "Epoch 62, Loss: 1.0499790906906128\n",
      "Epoch 63, Loss: 1.0533945560455322\n",
      "Epoch 64, Loss: 1.0484931468963623\n",
      "Epoch 65, Loss: 1.0502554178237915\n",
      "Epoch 66, Loss: 1.0574480295181274\n",
      "Epoch 67, Loss: 1.051154613494873\n",
      "Epoch 68, Loss: 1.0558844804763794\n",
      "Epoch 69, Loss: 1.0459595918655396\n",
      "Epoch 70, Loss: 1.0553280115127563\n",
      "Epoch 71, Loss: 1.0485771894454956\n",
      "Epoch 72, Loss: 1.0497639179229736\n",
      "Epoch 73, Loss: 1.0546557903289795\n",
      "Epoch 74, Loss: 1.047747015953064\n",
      "Epoch 75, Loss: 1.0487560033798218\n",
      "Epoch 76, Loss: 1.0428979396820068\n",
      "Epoch 77, Loss: 1.0474261045455933\n",
      "Epoch 78, Loss: 1.044944405555725\n",
      "Epoch 79, Loss: 1.0591593980789185\n",
      "Epoch 80, Loss: 1.0465779304504395\n",
      "Epoch 81, Loss: 1.0477423667907715\n",
      "Epoch 82, Loss: 1.0494778156280518\n",
      "Epoch 83, Loss: 1.0522459745407104\n",
      "Epoch 84, Loss: 1.0539699792861938\n",
      "Epoch 85, Loss: 1.0486843585968018\n",
      "Epoch 86, Loss: 1.0478252172470093\n",
      "Epoch 87, Loss: 1.047911286354065\n",
      "Epoch 88, Loss: 1.0440199375152588\n",
      "Epoch 89, Loss: 1.050028681755066\n",
      "Epoch 90, Loss: 1.0470706224441528\n",
      "Epoch 91, Loss: 1.0513765811920166\n",
      "Epoch 92, Loss: 1.0561070442199707\n",
      "Epoch 93, Loss: 1.0435127019882202\n",
      "Epoch 94, Loss: 1.0497649908065796\n",
      "Epoch 95, Loss: 1.0452901124954224\n",
      "Epoch 96, Loss: 1.0522313117980957\n",
      "Epoch 97, Loss: 1.0390950441360474\n",
      "Epoch 98, Loss: 1.0479016304016113\n",
      "Epoch 99, Loss: 1.0472991466522217\n",
      "Epoch 100, Loss: 1.038621425628662\n",
      "Epoch 101, Loss: 1.0550382137298584\n",
      "Epoch 102, Loss: 1.0499186515808105\n",
      "Epoch 103, Loss: 1.0432794094085693\n",
      "Epoch 104, Loss: 1.0498254299163818\n",
      "Epoch 105, Loss: 1.0424941778182983\n",
      "Epoch 106, Loss: 1.046260952949524\n",
      "Epoch 107, Loss: 1.0482962131500244\n",
      "Epoch 108, Loss: 1.0434057712554932\n",
      "Epoch 109, Loss: 1.0466476678848267\n",
      "Epoch 110, Loss: 1.0422110557556152\n",
      "Epoch 111, Loss: 1.0457147359848022\n",
      "Epoch 112, Loss: 1.0477420091629028\n",
      "Epoch 113, Loss: 1.0499669313430786\n",
      "Epoch 114, Loss: 1.0441440343856812\n",
      "Epoch 115, Loss: 1.0471482276916504\n",
      "Epoch 116, Loss: 1.0473079681396484\n",
      "Epoch 117, Loss: 1.0458120107650757\n",
      "Epoch 118, Loss: 1.047566294670105\n",
      "Epoch 119, Loss: 1.0436506271362305\n",
      "Epoch 120, Loss: 1.0457385778427124\n",
      "Epoch 121, Loss: 1.0396232604980469\n",
      "Epoch 122, Loss: 1.046147108078003\n",
      "Epoch 123, Loss: 1.054442286491394\n",
      "Epoch 124, Loss: 1.0517538785934448\n",
      "Epoch 125, Loss: 1.0403118133544922\n",
      "Epoch 126, Loss: 1.040144443511963\n",
      "Epoch 127, Loss: 1.0481117963790894\n",
      "Epoch 128, Loss: 1.0460219383239746\n",
      "Epoch 129, Loss: 1.0452028512954712\n",
      "Epoch 130, Loss: 1.0493642091751099\n",
      "Epoch 131, Loss: 1.0451011657714844\n",
      "Epoch 132, Loss: 1.042746901512146\n",
      "Epoch 133, Loss: 1.0461890697479248\n",
      "Epoch 134, Loss: 1.0414040088653564\n",
      "Epoch 135, Loss: 1.0519417524337769\n",
      "Epoch 136, Loss: 1.0431766510009766\n",
      "Epoch 137, Loss: 1.0508719682693481\n",
      "Epoch 138, Loss: 1.0460723638534546\n",
      "Epoch 139, Loss: 1.0412206649780273\n",
      "Epoch 140, Loss: 1.04911470413208\n",
      "Epoch 141, Loss: 1.0434603691101074\n",
      "Epoch 142, Loss: 1.0445226430892944\n",
      "Epoch 143, Loss: 1.0490347146987915\n",
      "Epoch 144, Loss: 1.0413758754730225\n",
      "Epoch 145, Loss: 1.0422953367233276\n",
      "Epoch 146, Loss: 1.0455466508865356\n",
      "Epoch 147, Loss: 1.0444121360778809\n",
      "Epoch 148, Loss: 1.0498411655426025\n",
      "Epoch 149, Loss: 1.0452003479003906\n",
      "Epoch 150, Loss: 1.0371384620666504\n",
      "Epoch 151, Loss: 1.0383429527282715\n",
      "Epoch 152, Loss: 1.0471315383911133\n",
      "Epoch 153, Loss: 1.0413217544555664\n",
      "Epoch 154, Loss: 1.0434190034866333\n",
      "Epoch 155, Loss: 1.046693205833435\n",
      "Epoch 156, Loss: 1.0421638488769531\n",
      "Epoch 157, Loss: 1.0476751327514648\n",
      "Epoch 158, Loss: 1.0403177738189697\n",
      "Epoch 159, Loss: 1.0435078144073486\n",
      "Epoch 160, Loss: 1.042807936668396\n",
      "Epoch 161, Loss: 1.0440961122512817\n",
      "Epoch 162, Loss: 1.0439836978912354\n",
      "Epoch 163, Loss: 1.0443049669265747\n",
      "Epoch 164, Loss: 1.0445500612258911\n",
      "Epoch 165, Loss: 1.0463380813598633\n",
      "Epoch 166, Loss: 1.040271282196045\n",
      "Epoch 167, Loss: 1.0490219593048096\n",
      "Epoch 168, Loss: 1.0410281419754028\n",
      "Epoch 169, Loss: 1.0485401153564453\n",
      "Epoch 170, Loss: 1.0440361499786377\n",
      "Epoch 171, Loss: 1.0411787033081055\n",
      "Epoch 172, Loss: 1.0496819019317627\n",
      "Epoch 173, Loss: 1.0462993383407593\n",
      "Epoch 174, Loss: 1.0459321737289429\n",
      "Epoch 175, Loss: 1.0428916215896606\n",
      "Epoch 176, Loss: 1.040928602218628\n",
      "Epoch 177, Loss: 1.0464575290679932\n",
      "Epoch 178, Loss: 1.0412203073501587\n",
      "Epoch 179, Loss: 1.0449888706207275\n",
      "Epoch 180, Loss: 1.0383737087249756\n",
      "Epoch 181, Loss: 1.042191505432129\n",
      "Epoch 182, Loss: 1.0501573085784912\n",
      "Epoch 183, Loss: 1.0454081296920776\n",
      "Epoch 184, Loss: 1.038461685180664\n",
      "Epoch 185, Loss: 1.041111707687378\n",
      "Epoch 186, Loss: 1.0465151071548462\n",
      "Epoch 187, Loss: 1.0475901365280151\n",
      "Epoch 188, Loss: 1.0450294017791748\n",
      "Epoch 189, Loss: 1.034936785697937\n",
      "Epoch 190, Loss: 1.052047848701477\n",
      "Epoch 191, Loss: 1.0392744541168213\n",
      "Epoch 192, Loss: 1.0398515462875366\n",
      "Epoch 193, Loss: 1.0451173782348633\n",
      "Epoch 194, Loss: 1.0356978178024292\n",
      "Epoch 195, Loss: 1.0366737842559814\n",
      "Epoch 196, Loss: 1.043525218963623\n",
      "Epoch 197, Loss: 1.041593313217163\n",
      "Epoch 198, Loss: 1.043532133102417\n",
      "Epoch 199, Loss: 1.0416464805603027\n",
      "Epoch 200, Loss: 1.0433001518249512\n",
      "Epoch 201, Loss: 1.0449610948562622\n",
      "Epoch 202, Loss: 1.0377066135406494\n",
      "Epoch 203, Loss: 1.047709584236145\n",
      "Epoch 204, Loss: 1.0467627048492432\n",
      "Epoch 205, Loss: 1.0454967021942139\n",
      "Epoch 206, Loss: 1.0421273708343506\n",
      "Epoch 207, Loss: 1.039304256439209\n",
      "Epoch 208, Loss: 1.042312741279602\n",
      "Epoch 209, Loss: 1.040765643119812\n",
      "Epoch 210, Loss: 1.0431278944015503\n",
      "Epoch 211, Loss: 1.0440645217895508\n",
      "Epoch 212, Loss: 1.0381348133087158\n",
      "Epoch 213, Loss: 1.0353878736495972\n",
      "Epoch 214, Loss: 1.0449124574661255\n",
      "Epoch 215, Loss: 1.0397405624389648\n",
      "Epoch 216, Loss: 1.0410184860229492\n",
      "Epoch 217, Loss: 1.0399699211120605\n",
      "Epoch 218, Loss: 1.0403635501861572\n",
      "Epoch 219, Loss: 1.0379078388214111\n",
      "Epoch 220, Loss: 1.0400581359863281\n",
      "Epoch 221, Loss: 1.0514439344406128\n",
      "Epoch 222, Loss: 1.0488463640213013\n",
      "Epoch 223, Loss: 1.041035771369934\n",
      "Epoch 224, Loss: 1.0402486324310303\n",
      "Epoch 225, Loss: 1.0407761335372925\n",
      "Epoch 226, Loss: 1.0475364923477173\n",
      "Epoch 227, Loss: 1.0398694276809692\n",
      "Epoch 228, Loss: 1.0392515659332275\n",
      "Epoch 229, Loss: 1.051238775253296\n",
      "Epoch 230, Loss: 1.0395004749298096\n",
      "Epoch 231, Loss: 1.0402311086654663\n",
      "Epoch 232, Loss: 1.0402584075927734\n",
      "Epoch 233, Loss: 1.0346848964691162\n",
      "Epoch 234, Loss: 1.0452320575714111\n",
      "Epoch 235, Loss: 1.0435017347335815\n",
      "Epoch 236, Loss: 1.0325793027877808\n",
      "Epoch 237, Loss: 1.042621374130249\n",
      "Epoch 238, Loss: 1.0307904481887817\n",
      "Epoch 239, Loss: 1.0522520542144775\n",
      "Epoch 240, Loss: 1.0441235303878784\n",
      "Epoch 241, Loss: 1.0396379232406616\n",
      "Epoch 242, Loss: 1.0379410982131958\n",
      "Epoch 243, Loss: 1.042991280555725\n",
      "Epoch 244, Loss: 1.039368748664856\n",
      "Epoch 245, Loss: 1.0354087352752686\n",
      "Epoch 246, Loss: 1.0377217531204224\n",
      "Epoch 247, Loss: 1.0372710227966309\n",
      "Epoch 248, Loss: 1.0442137718200684\n",
      "Epoch 249, Loss: 1.0356916189193726\n",
      "Epoch 250, Loss: 1.040207028388977\n",
      "Epoch 251, Loss: 1.047619104385376\n",
      "Epoch 252, Loss: 1.0487675666809082\n",
      "Epoch 253, Loss: 1.0421183109283447\n",
      "Epoch 254, Loss: 1.042291283607483\n",
      "Epoch 255, Loss: 1.0397822856903076\n",
      "Epoch 256, Loss: 1.0411031246185303\n",
      "Epoch 257, Loss: 1.0377761125564575\n",
      "Epoch 258, Loss: 1.0446271896362305\n",
      "Epoch 259, Loss: 1.047542929649353\n",
      "Epoch 260, Loss: 1.0454336404800415\n",
      "Epoch 261, Loss: 1.036888837814331\n",
      "Epoch 262, Loss: 1.0414979457855225\n",
      "Epoch 263, Loss: 1.0362129211425781\n",
      "Epoch 264, Loss: 1.043741226196289\n",
      "Epoch 265, Loss: 1.03963041305542\n",
      "Epoch 266, Loss: 1.0443854331970215\n",
      "Epoch 267, Loss: 1.0441163778305054\n",
      "Epoch 268, Loss: 1.041469931602478\n",
      "Epoch 269, Loss: 1.0423461198806763\n",
      "Epoch 270, Loss: 1.0362547636032104\n",
      "Epoch 271, Loss: 1.0426740646362305\n",
      "Epoch 272, Loss: 1.0360181331634521\n",
      "Epoch 273, Loss: 1.0340427160263062\n",
      "Epoch 274, Loss: 1.0380533933639526\n",
      "Epoch 275, Loss: 1.0432744026184082\n",
      "Epoch 276, Loss: 1.033747911453247\n",
      "Epoch 277, Loss: 1.0443966388702393\n",
      "Epoch 278, Loss: 1.0397158861160278\n",
      "Epoch 279, Loss: 1.0430305004119873\n",
      "Epoch 280, Loss: 1.0351994037628174\n",
      "Epoch 281, Loss: 1.0418263673782349\n",
      "Epoch 282, Loss: 1.048599362373352\n",
      "Epoch 283, Loss: 1.0387555360794067\n",
      "Epoch 284, Loss: 1.0332200527191162\n",
      "Epoch 285, Loss: 1.0473382472991943\n",
      "Epoch 286, Loss: 1.0437129735946655\n",
      "Epoch 287, Loss: 1.0438786745071411\n",
      "Epoch 288, Loss: 1.0329328775405884\n",
      "Epoch 289, Loss: 1.0372833013534546\n",
      "Epoch 290, Loss: 1.0386840105056763\n",
      "Epoch 291, Loss: 1.0407298803329468\n",
      "Epoch 292, Loss: 1.0520315170288086\n",
      "Epoch 293, Loss: 1.0330569744110107\n",
      "Epoch 294, Loss: 1.0371057987213135\n",
      "Epoch 295, Loss: 1.0391194820404053\n",
      "Epoch 296, Loss: 1.0375125408172607\n",
      "Epoch 297, Loss: 1.0425374507904053\n",
      "Epoch 298, Loss: 1.043675422668457\n",
      "Epoch 299, Loss: 1.0399144887924194\n",
      "Epoch 300, Loss: 1.0375558137893677\n",
      "Epoch 301, Loss: 1.0430911779403687\n",
      "Epoch 302, Loss: 1.0425907373428345\n",
      "Epoch 303, Loss: 1.0406646728515625\n",
      "Epoch 304, Loss: 1.0432616472244263\n",
      "Epoch 305, Loss: 1.0454771518707275\n",
      "Epoch 306, Loss: 1.0422192811965942\n",
      "Epoch 307, Loss: 1.048067569732666\n",
      "Epoch 308, Loss: 1.0430023670196533\n",
      "Epoch 309, Loss: 1.041700839996338\n",
      "Epoch 310, Loss: 1.0389961004257202\n",
      "Epoch 311, Loss: 1.0405089855194092\n",
      "Epoch 312, Loss: 1.0447020530700684\n",
      "Epoch 313, Loss: 1.0424139499664307\n",
      "Epoch 314, Loss: 1.0409260988235474\n",
      "Epoch 315, Loss: 1.0410743951797485\n",
      "Epoch 316, Loss: 1.0444936752319336\n",
      "Epoch 317, Loss: 1.0388157367706299\n",
      "Epoch 318, Loss: 1.0398274660110474\n",
      "Epoch 319, Loss: 1.0405871868133545\n",
      "Epoch 320, Loss: 1.031090259552002\n",
      "Epoch 321, Loss: 1.0319613218307495\n",
      "Epoch 322, Loss: 1.0386399030685425\n",
      "Epoch 323, Loss: 1.0369170904159546\n",
      "Epoch 324, Loss: 1.03965163230896\n",
      "Epoch 325, Loss: 1.0432884693145752\n",
      "Epoch 326, Loss: 1.0459332466125488\n",
      "Epoch 327, Loss: 1.0448591709136963\n",
      "Epoch 328, Loss: 1.04123854637146\n",
      "Epoch 329, Loss: 1.0436925888061523\n",
      "Epoch 330, Loss: 1.0405381917953491\n",
      "Epoch 331, Loss: 1.0405244827270508\n",
      "Epoch 332, Loss: 1.0344266891479492\n",
      "Epoch 333, Loss: 1.037563681602478\n",
      "Epoch 334, Loss: 1.034531593322754\n",
      "Epoch 335, Loss: 1.052797794342041\n",
      "Epoch 336, Loss: 1.0368295907974243\n",
      "Epoch 337, Loss: 1.0394622087478638\n",
      "Epoch 338, Loss: 1.034593105316162\n",
      "Epoch 339, Loss: 1.0443674325942993\n",
      "Epoch 340, Loss: 1.0402785539627075\n",
      "Epoch 341, Loss: 1.0372308492660522\n",
      "Epoch 342, Loss: 1.036926031112671\n",
      "Epoch 343, Loss: 1.0403032302856445\n",
      "Epoch 344, Loss: 1.033711314201355\n",
      "Epoch 345, Loss: 1.042280912399292\n",
      "Epoch 346, Loss: 1.0422532558441162\n",
      "Epoch 347, Loss: 1.0396292209625244\n",
      "Epoch 348, Loss: 1.0432723760604858\n",
      "Epoch 349, Loss: 1.0514849424362183\n",
      "Epoch 350, Loss: 1.0301481485366821\n",
      "Epoch 351, Loss: 1.0366955995559692\n",
      "Epoch 352, Loss: 1.043087124824524\n",
      "Epoch 353, Loss: 1.0386179685592651\n",
      "Epoch 354, Loss: 1.0380511283874512\n",
      "Epoch 355, Loss: 1.036726474761963\n",
      "Epoch 356, Loss: 1.0428199768066406\n",
      "Epoch 357, Loss: 1.0403975248336792\n",
      "Epoch 358, Loss: 1.0383038520812988\n",
      "Epoch 359, Loss: 1.040489912033081\n",
      "Epoch 360, Loss: 1.0397405624389648\n",
      "Epoch 361, Loss: 1.0396828651428223\n",
      "Epoch 362, Loss: 1.041793942451477\n",
      "Epoch 363, Loss: 1.0415873527526855\n",
      "Epoch 364, Loss: 1.040536880493164\n",
      "Epoch 365, Loss: 1.0425013303756714\n",
      "Epoch 366, Loss: 1.037821888923645\n",
      "Epoch 367, Loss: 1.042540192604065\n",
      "Epoch 368, Loss: 1.0363255739212036\n",
      "Epoch 369, Loss: 1.038200855255127\n",
      "Epoch 370, Loss: 1.032697081565857\n",
      "Epoch 371, Loss: 1.0402379035949707\n",
      "Epoch 372, Loss: 1.0437968969345093\n",
      "Epoch 373, Loss: 1.0412442684173584\n",
      "Epoch 374, Loss: 1.0444673299789429\n",
      "Epoch 375, Loss: 1.0393052101135254\n",
      "Epoch 376, Loss: 1.0327506065368652\n",
      "Epoch 377, Loss: 1.039942979812622\n",
      "Epoch 378, Loss: 1.039906620979309\n",
      "Epoch 379, Loss: 1.0403157472610474\n",
      "Epoch 380, Loss: 1.0469377040863037\n",
      "Epoch 381, Loss: 1.0353749990463257\n",
      "Epoch 382, Loss: 1.0328478813171387\n",
      "Epoch 383, Loss: 1.0401420593261719\n",
      "Epoch 384, Loss: 1.0460346937179565\n",
      "Epoch 385, Loss: 1.0413663387298584\n",
      "Epoch 386, Loss: 1.0411015748977661\n",
      "Epoch 387, Loss: 1.0372225046157837\n",
      "Epoch 388, Loss: 1.0442454814910889\n",
      "Epoch 389, Loss: 1.0467644929885864\n",
      "Epoch 390, Loss: 1.0422946214675903\n",
      "Epoch 391, Loss: 1.0385338068008423\n",
      "Epoch 392, Loss: 1.03171968460083\n",
      "Epoch 393, Loss: 1.0401420593261719\n",
      "Epoch 394, Loss: 1.045413613319397\n",
      "Epoch 395, Loss: 1.0432541370391846\n",
      "Epoch 396, Loss: 1.0414365530014038\n",
      "Epoch 397, Loss: 1.0372371673583984\n",
      "Epoch 398, Loss: 1.0403386354446411\n",
      "Epoch 399, Loss: 1.0351697206497192\n",
      "Epoch 400, Loss: 1.0420504808425903\n",
      "Epoch 401, Loss: 1.037978172302246\n",
      "Epoch 402, Loss: 1.0482362508773804\n",
      "Epoch 403, Loss: 1.0326457023620605\n",
      "Epoch 404, Loss: 1.042718529701233\n",
      "Epoch 405, Loss: 1.0396212339401245\n",
      "Epoch 406, Loss: 1.0456095933914185\n",
      "Epoch 407, Loss: 1.035731315612793\n",
      "Epoch 408, Loss: 1.0374386310577393\n",
      "Epoch 409, Loss: 1.0474731922149658\n",
      "Epoch 410, Loss: 1.0450788736343384\n",
      "Epoch 411, Loss: 1.033735990524292\n",
      "Epoch 412, Loss: 1.0417529344558716\n",
      "Epoch 413, Loss: 1.0326849222183228\n",
      "Epoch 414, Loss: 1.0365421772003174\n",
      "Epoch 415, Loss: 1.04813551902771\n",
      "Epoch 416, Loss: 1.0331299304962158\n",
      "Epoch 417, Loss: 1.0406194925308228\n",
      "Epoch 418, Loss: 1.046328067779541\n",
      "Epoch 419, Loss: 1.0404223203659058\n",
      "Epoch 420, Loss: 1.0360398292541504\n",
      "Epoch 421, Loss: 1.0337382555007935\n",
      "Epoch 422, Loss: 1.0402722358703613\n",
      "Epoch 423, Loss: 1.046126365661621\n",
      "Epoch 424, Loss: 1.0412567853927612\n",
      "Epoch 425, Loss: 1.0410654544830322\n",
      "Epoch 426, Loss: 1.0494356155395508\n",
      "Epoch 427, Loss: 1.0419199466705322\n",
      "Epoch 428, Loss: 1.0401465892791748\n",
      "Epoch 429, Loss: 1.037186861038208\n",
      "Epoch 430, Loss: 1.045504093170166\n",
      "Epoch 431, Loss: 1.0434726476669312\n",
      "Epoch 432, Loss: 1.0429155826568604\n",
      "Epoch 433, Loss: 1.0429680347442627\n",
      "Epoch 434, Loss: 1.0356905460357666\n",
      "Epoch 435, Loss: 1.0360352993011475\n",
      "Epoch 436, Loss: 1.0346144437789917\n",
      "Epoch 437, Loss: 1.0409375429153442\n",
      "Epoch 438, Loss: 1.0447423458099365\n",
      "Epoch 439, Loss: 1.0332096815109253\n",
      "Epoch 440, Loss: 1.041406512260437\n",
      "Epoch 441, Loss: 1.0397778749465942\n",
      "Epoch 442, Loss: 1.0371158123016357\n",
      "Epoch 443, Loss: 1.036098837852478\n",
      "Epoch 444, Loss: 1.0346758365631104\n",
      "Epoch 445, Loss: 1.030600905418396\n",
      "Epoch 446, Loss: 1.040879249572754\n",
      "Epoch 447, Loss: 1.0379307270050049\n",
      "Epoch 448, Loss: 1.0414060354232788\n",
      "Epoch 449, Loss: 1.037604570388794\n",
      "Epoch 450, Loss: 1.0509928464889526\n",
      "Epoch 451, Loss: 1.0419589281082153\n",
      "Epoch 452, Loss: 1.0417840480804443\n",
      "Epoch 453, Loss: 1.0366930961608887\n",
      "Epoch 454, Loss: 1.0416743755340576\n",
      "Epoch 455, Loss: 1.0404536724090576\n",
      "Epoch 456, Loss: 1.0380228757858276\n",
      "Epoch 457, Loss: 1.039061427116394\n",
      "Epoch 458, Loss: 1.0354801416397095\n",
      "Epoch 459, Loss: 1.0355015993118286\n",
      "Epoch 460, Loss: 1.0363423824310303\n",
      "Epoch 461, Loss: 1.049261212348938\n",
      "Epoch 462, Loss: 1.0409119129180908\n",
      "Epoch 463, Loss: 1.0388994216918945\n",
      "Epoch 464, Loss: 1.0332763195037842\n",
      "Epoch 465, Loss: 1.037112832069397\n",
      "Epoch 466, Loss: 1.0379773378372192\n",
      "Epoch 467, Loss: 1.034140706062317\n",
      "Epoch 468, Loss: 1.0398383140563965\n",
      "Epoch 469, Loss: 1.039003610610962\n",
      "Epoch 470, Loss: 1.0478956699371338\n",
      "Epoch 471, Loss: 1.037092685699463\n",
      "Epoch 472, Loss: 1.0296915769577026\n",
      "Epoch 473, Loss: 1.031990647315979\n",
      "Epoch 474, Loss: 1.03646719455719\n",
      "Epoch 475, Loss: 1.0463730096817017\n",
      "Epoch 476, Loss: 1.0322483777999878\n",
      "Epoch 477, Loss: 1.0456310510635376\n",
      "Epoch 478, Loss: 1.043611764907837\n",
      "Epoch 479, Loss: 1.043351173400879\n",
      "Epoch 480, Loss: 1.0384782552719116\n",
      "Epoch 481, Loss: 1.0430134534835815\n",
      "Epoch 482, Loss: 1.0308141708374023\n",
      "Epoch 483, Loss: 1.039466142654419\n",
      "Epoch 484, Loss: 1.0327379703521729\n",
      "Epoch 485, Loss: 1.0265529155731201\n",
      "Epoch 486, Loss: 1.0334609746932983\n",
      "Epoch 487, Loss: 1.0311177968978882\n",
      "Epoch 488, Loss: 1.033294677734375\n",
      "Epoch 489, Loss: 1.043779730796814\n",
      "Epoch 490, Loss: 1.0375418663024902\n",
      "Epoch 491, Loss: 1.037662148475647\n",
      "Epoch 492, Loss: 1.0418739318847656\n",
      "Epoch 493, Loss: 1.0403026342391968\n",
      "Epoch 494, Loss: 1.0335948467254639\n",
      "Epoch 495, Loss: 1.0337797403335571\n",
      "Epoch 496, Loss: 1.040012001991272\n",
      "Epoch 497, Loss: 1.0351431369781494\n",
      "Epoch 498, Loss: 1.0419024229049683\n",
      "Epoch 499, Loss: 1.0452674627304077\n",
      "Epoch 500, Loss: 1.0416862964630127\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/NHL_with_headers.csv')\n",
    "df['time'] = pd.to_datetime(df['time'], format='%d-%m-%y')\n",
    "df = df.drop(columns=['home_score', 'away_score', 'difference_score'])\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)  # Shuffle the dataframe\n",
    "\n",
    "\n",
    "# Convert teams to integers\n",
    "team_to_int = {team: i for i, team in enumerate(pd.concat([df['home_team'], df['away_team']]).unique())}\n",
    "df['home_team'] = df['home_team'].map(team_to_int)\n",
    "df['away_team'] = df['away_team'].map(team_to_int)\n",
    "\n",
    "# Convert results to integers\n",
    "result_map = {'W': 2, 'D': 1, 'L': 0}\n",
    "df['result'] = df['result'].map(result_map)\n",
    "\n",
    "\n",
    "\n",
    "# Split into training and test datasets (80%-20%)\n",
    "train_df = df[:int(0.8 * len(df))]\n",
    "test_df = df[int(0.8 * len(df)):]\n",
    "\n",
    "# Function to create Data instance from dataframe\n",
    "def create_data_from_df(df):\n",
    "    edge_index = torch.tensor(df[['home_team', 'away_team']].values).t().contiguous()\n",
    "    x = torch.tensor(df[['home_shots', 'away_shots', 'home_hits', 'away_hits']].values, dtype=torch.float)\n",
    "    #x = torch.tensor(df[['home_score', 'away_score', 'difference_score', 'home_shots', 'away_shots', 'home_hits', 'away_hits']].values, dtype=torch.float)\n",
    "    y = torch.tensor(df['result'].values)\n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "train_data = create_data_from_df(train_df)\n",
    "test_data = create_data_from_df(test_df)\n",
    "\n",
    "\n",
    "# GNN Model\n",
    "class GNN_new(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(GNN_new, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, 128)\n",
    "        self.conv2 = GCNConv(128, 3)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GNN_new(train_data.x.size(1))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Training\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data)\n",
    "    loss = F.nll_loss(out, train_data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "losses = []\n",
    "for epoch in range(500):\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss}')\n",
    "pd.Series(losses).plot()\n",
    "#savefig('loss_gnn_norm.png')\n",
    "#fig2 = plt.gcf()\n",
    "#fig2.savefig('loss_gnn_norm.png')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_out = model(test_data)\n",
    "    _, predicted_test = test_out.max(dim=1)\n",
    "\n",
    "# Actual results\n",
    "y_true = test_data.y.numpy()\n",
    "\n",
    "# Predictions\n",
    "y_pred = predicted_test.numpy()\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(test_data.y, predicted_test, labels=[2, 1, 0])  # Assuming labels are 2 for \"W\", 1 for \"D\", and 2 for \"L\"\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"W\", \"D\", \"L\"])\n",
    "disp.plot(cmap='Blues')\n",
    "#fig1 = plt.gcf()\n",
    "plt.show()\n",
    "#fig1.savefig('cm_gnn_norm.png')\n",
    "\n",
    "score = accuracy_score(y_true, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20303a82-9873-4126-b36d-9b2b0ab873b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0 (from torch)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.0.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.1)\n",
      "Collecting cmake (from triton==2.0.0->torch)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/2e/51/3a4672a819b4532a378bfefad8f886cfe71057556e0d4eefb64523fd370a/cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lit (from triton==2.0.0->torch)\n",
      "  Downloading lit-16.0.6.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m153.7/153.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93584 sha256=b6b1c7a02d141751fe6ce6ca95d5dd242edc0265f77723358b967b2bd24ab174\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/14/f9/07/bb2308587bc2f57158f905a2325f6a89a2befa7437b2d7e137\n",
      "Successfully built lit\n",
      "Installing collected packages: mpmath, lit, cmake, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "Successfully installed cmake-3.27.2 lit-16.0.6 mpmath-1.3.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 triton-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f593bc-96e4-446b-bad5-7afd40c3109d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.65.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.3.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=b7bd986f9f9025f61fbaf193f7390508aba0d83c2cd290f322b320576513cae2\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62d4517e-7f14-4cc0-8637-15cdbe210264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Conv GNN network\n",
    "import torch\n",
    "from torch.nn import LogSoftmax, ReLU, Tanh, LeakyReLU, ModuleList, Dropout\n",
    "from torch_geometric.nn import GCNConv, GraphConv, ChebConv\n",
    "\n",
    "target_dim = 3\n",
    "\n",
    "activations = {\n",
    "    'relu': ReLU(),\n",
    "    'tanh': Tanh(),\n",
    "    'leaky': LeakyReLU()\n",
    "}\n",
    "\n",
    "\n",
    "class GNNModel_from_paper(torch.nn.Module):\n",
    "    def __init__(self, num_teams, embed_dim=10, n_conv=3, conv_dims=(32, 32, 32, 16), n_dense=5, dense_dims=(8, 8, 8, 8,8),\n",
    "                 act_f='leaky', **kwargs):\n",
    "        super(GNNModel_from_paper, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_conv = n_conv\n",
    "        self.conv_dims = conv_dims\n",
    "        self.n_dense = n_dense\n",
    "        self.activation = activations[act_f]\n",
    "        self.num_teams = num_teams\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=num_teams, embedding_dim=embed_dim)\n",
    "\n",
    "        conv_layers = [GraphConv(self.embed_dim, self.conv_dims[0])]\n",
    "        for i in range(n_conv - 1):\n",
    "            conv_layers.append(GraphConv(conv_dims[i], conv_dims[i + 1]))\n",
    "        self.conv_layers = ModuleList(conv_layers)\n",
    "\n",
    "        lin_layers = []\n",
    "        lin_layers.append(torch.nn.Linear(conv_dims[n_conv - 1]*2, dense_dims[0]))\n",
    "        for i in range(n_dense - 2):\n",
    "            lin_layers.append(torch.nn.Linear(dense_dims[i], dense_dims[i + 1]))\n",
    "        lin_layers.append(torch.nn.Linear(dense_dims[n_dense - 2], target_dim))\n",
    "\n",
    "        self.lin_layers = ModuleList(lin_layers)\n",
    "\n",
    "        self.out = LogSoftmax(dim=1)\n",
    "        self.drop = Dropout(p=0.1)\n",
    "\n",
    "\n",
    "    def forward(self, data, home, away):\n",
    "        edge_index, edge_weight = data.edge_index, data.edge_weight\n",
    "        if hasattr(self, 'num_teams'):\n",
    "            num_teams = self.num_teams\n",
    "        else:\n",
    "            num_teams = data.n_teams\n",
    "        x = torch.tensor(list(range(num_teams)))\n",
    "        x = self.embedding(x).reshape(-1, self.embed_dim)\n",
    "\n",
    "        if len(edge_weight) > 0:\n",
    "            x = self.conv_layers[0](x, edge_index, edge_weight )\n",
    "        else:\n",
    "            x = self.conv_layers[0](x, edge_index)\n",
    "        x = self.activation(x)\n",
    "        x = self.drop(x)\n",
    "\n",
    "        for i in range(self.n_conv - 1):\n",
    "            if len(edge_weight) > 0:\n",
    "                    x = self.activation(self.conv_layers[i + 1](x, data.edge_index, edge_weight))\n",
    "            else:\n",
    "                x = self.activation(self.conv_layers[i + 1](x, data.edge_index))\n",
    "            # x = self.drop(x)\n",
    "\n",
    "        x = torch.cat([x[home], x[away]], dim=1)\n",
    "        # x = torch.sub(x[home], x[away])\n",
    "\n",
    "        for i in range(self.n_dense):\n",
    "            x = self.activation(self.lin_layers[i](x))\n",
    "            x = self.drop(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x.reshape(-1, target_dim)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01a4b407-7192-48c4-86ce-b7bdd0ad1976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding, Linear, Dropout, ModuleList\n",
    "from torch.nn import LogSoftmax, ReLU, Tanh, LeakyReLU\n",
    "\n",
    "activations = {\n",
    "    'relu': ReLU(),\n",
    "    'tanh': Tanh(),\n",
    "    'leaky': LeakyReLU(0.2)\n",
    "}\n",
    "\n",
    "\n",
    "class FlatModel(torch.nn.Module):\n",
    "    def __init__(self, n_teams, out_dim=3, embed_dim=10, pretrained_weights=None, n_dense=4, dense_dims=(4,4,4,32),\n",
    "                 act_f='leaky', **kwargs):\n",
    "        super(FlatModel, self).__init__()\n",
    "        # set hyperparameters for the model\n",
    "        self.n_teams = n_teams\n",
    "        self.out_dim = out_dim\n",
    "        self.activation = activations[act_f]\n",
    "        self.n_dense = n_dense\n",
    "\n",
    "        # set the layers to be used in the model\n",
    "        if pretrained_weights is not None:\n",
    "            self.embedding = Embedding.from_pretrained(pretrained_weights)\n",
    "        else:\n",
    "            self.embedding = Embedding(n_teams, embed_dim)\n",
    "\n",
    "        lin_layers = []\n",
    "        lin_layers.append(torch.nn.Linear(embed_dim * 2, dense_dims[0]))\n",
    "        for i in range(n_dense - 2):\n",
    "            lin_layers.append(torch.nn.Linear(dense_dims[i], dense_dims[i + 1]))\n",
    "        lin_layers.append(torch.nn.Linear(dense_dims[n_dense - 2], self.out_dim))\n",
    "        self.lin_layers = ModuleList(lin_layers)\n",
    "\n",
    "        self.out = LogSoftmax(dim=1)\n",
    "\n",
    "        self.drop = Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, data, team_home, team_away):\n",
    "        home_emb = self.embedding(team_home)\n",
    "        away_emb = self.embedding(team_away)\n",
    "        x = torch.cat((home_emb, away_emb), 1)\n",
    "\n",
    "        for layer in self.lin_layers:\n",
    "            x = self.activation(layer(x))\n",
    "            x = self.drop(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x.reshape(-1, self.out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0ef9a-5bbe-4c62-9021-0928e01a8b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc19b710-151c-4321-8de8-0a2c9d89bc52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from typing import Tuple\n",
    "import pickle\n",
    "from itertools import permutations\n",
    "import numpy.ma as ma\n",
    "\n",
    "\n",
    "input_filename = \"data/NHL.csv\"\n",
    "model_name = \"GNNModel_from_paper\"\n",
    "\n",
    "#dataset = pd.read_csv('data/NHL.csv', header=None)\n",
    "#dataset.columns = ['year', 'league', 'time', 'home_team', 'away_team', 'home_score', 'away_score', 'difference_score','result', 'country', 'home_shots', 'away_shots','home_hits','away_hits']\n",
    "names = ['year', 'league', 'time', 'home_team', 'away_team', 'home_score', 'away_score', 'difference_score','result', 'country', 'home_shots', 'away_shots','home_hits','away_hits']\n",
    "\n",
    "#num_teams = len(pd.concat([dataset['home_team'], dataset['away_team']]).unique())\n",
    "#model = GNNModel_from_paper(num_teams=num_teams)\n",
    "\n",
    "\n",
    "class DataTransformer:\n",
    "    def __init__(self, filename: str):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "        self.data_train = None\n",
    "        self.data_val = None\n",
    "        self.data_test = None\n",
    "        self.n_teams = None\n",
    "\n",
    "        self.read_data()\n",
    "        self.data = self.clean_data(self.data)\n",
    "        self.N = self.data.shape[0]\n",
    "        self.fit_encoder()\n",
    "        # self.prepare_data()\n",
    "\n",
    "    def read_data(self):\n",
    "        \"\"\"Read the data from csv with correct data types.\"\"\"\n",
    "        #dataset = pd.read_csv('data/NHL.csv', header=None)\n",
    "        self.data = pd.read_csv(self.filename, header=None, names=names,\n",
    "                                dtype=dict(zip(names, [int] + [str] * 4 + [int] * 3 + [str] * 2 + [int]*4)))\n",
    "\n",
    "    def clean_data(self,data, convert_to_numpy=False, allow_draw=True) :\n",
    "        \"\"\"Add a column to transform result of the match into int, \"\"\"\n",
    "        # result ot int\n",
    "        conditions = [\n",
    "            (data['result'] == 'W'),\n",
    "            (data['result'] == 'D'),\n",
    "            (data['result'] == 'L')]\n",
    "        choices = [2,1,0]\n",
    "        data['lwd'] = np.select(conditions, choices)\n",
    "        if names[-1] != 'lwd':\n",
    "            names.append('lwd')\n",
    "        # ignore the draw results\n",
    "        if not allow_draw:\n",
    "            data = self.data[self.data['result'] != 'D']\n",
    "        if convert_to_numpy:\n",
    "            data = self.data.to_numpy()\n",
    "        return data\n",
    "\n",
    "    def fit_encoder(self):\n",
    "        data = self.data\n",
    "        data = data.to_numpy()\n",
    "        teams = np.unique(data[:, [3, 4]])\n",
    "        self.n_teams = len(teams)\n",
    "        X = data[:, [3, 4]]\n",
    "        X = X.flatten()\n",
    "        self.label_encoder.fit(X)\n",
    "\n",
    "    def encode_teams(self, data):\n",
    "        data = data.to_numpy()\n",
    "        teams = np.unique(data[:, [3, 4]])\n",
    "        # self.n_teams = len(teams)\n",
    "        X = data[:, [3, 4]]\n",
    "\n",
    "        X = X.flatten()\n",
    "        X = self.label_encoder.transform(X)\n",
    "        teams_encoded = self.label_encoder.transform(teams)\n",
    "        teams_encoded = pd.DataFrame({'teams': teams, 'label_encoding': teams_encoded})\n",
    "\n",
    "        data[:, [3, 4]] = np.reshape(X, (-1, 2))\n",
    "        return data, teams_encoded\n",
    "\n",
    "\n",
    "    def prepare_data(self, data=None, split_to_test=True, save_to_self=False):\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "\n",
    "        data, teams_encoded = self.encode_teams(data)\n",
    "\n",
    "        if split_to_test:\n",
    "            separator_val = int(data.__len__() * 0.8)\n",
    "            separator_test = int(data.__len__() * 0.9)\n",
    "            # separator_test_final = int(int(data.__len__() * 0.9))\n",
    "            data_train = pd.DataFrame(data=data[:separator_val], columns=names)\n",
    "            data_val = pd.DataFrame(data=data[separator_val:separator_test], columns=names)\n",
    "            data_test = pd.DataFrame(data=data[separator_test:], columns=names)\n",
    "            data_test_final = []\n",
    "            # data_test_final = pd.DataFrame(data=data[separator_test_final:], columns=names)\n",
    "            self.print_metadata(data_train, \"train\")\n",
    "            self.print_metadata(data_val, \"val\")\n",
    "            self.print_metadata(data_test, \"test\")\n",
    "            if save_to_self:\n",
    "                self.data_train = data_train\n",
    "                self.data_val = data_val\n",
    "                self.data_test = data_test\n",
    "            self.N = data.shape[0]\n",
    "            return data_train, data_val, data_test, data_test_final, teams_encoded\n",
    "        else:\n",
    "            data = pd.DataFrame(data=data, columns=names)\n",
    "            if save_to_self:\n",
    "                self.data = data\n",
    "            return self.data, teams_encoded\n",
    "\n",
    "    def to_tensor(self,data):\n",
    "        home = torch.tensor(data['home_team'].values.astype(int)).to(torch.int64)\n",
    "        away = torch.tensor(data['away_team'].values.astype(int)).to(torch.int64)\n",
    "        label = data['lwd'].values.astype(int).reshape(-1,1)\n",
    "        # self.ohe = OneHotEncoder()\n",
    "        # self.ohe.fit(label)\n",
    "        # label = self.ohe.transform(label).toarray()\n",
    "\n",
    "        label = torch.tensor(label).to(torch.int64)\n",
    "        return home, away, label\n",
    "\n",
    "    def get_train_data(self):\n",
    "        self.print_metadata(self.data_train, \"Information on Train data: \")\n",
    "        home, away, label = self.to_tensor(self.data_train)\n",
    "        return home, away, label\n",
    "\n",
    "    def get_test_data(self):\n",
    "        self.print_metadata(self.data_test, \"Information on Test data: \")\n",
    "        home, away, label = self.to_tensor(self.data_test)\n",
    "        return home, away, label\n",
    "\n",
    "    @staticmethod\n",
    "    def print_metadata(data, message=\"\"):\n",
    "        # print some metadata\n",
    "        won = data[data['result'] == \"W\"].shape[0]\n",
    "        lost = data[data['result'] == \"L\"].shape[0]\n",
    "        draw = data[data['result'] == \"D\"].shape[0]\n",
    "        total = data.shape[0]\n",
    "        # print(\"Won:\", won, won / total * 100, \", Lost:\", lost, lost / total * 100)\n",
    "        print(\"Total {} data points: {}, Won: {}%, Lost: {}%, Draw: {}%\".format(message, total, won*100 / total, lost*100 / total, draw*100 / total))\n",
    "        # print(\"The number of data points in the data set is:\", total)\n",
    "\t\t\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "\n",
    "        dt = DataTransformer(self.filename)\n",
    "        grouped = dt.data.groupby(['league'])\n",
    "        for league_year, group in tqdm(grouped):\n",
    "            data_train, data_val, data_test, data_test_final, teams_enc = dt.prepare_data(data=group)\n",
    "            n_teams = len(teams_enc['teams'].values)\n",
    "            win_lose_network = np.zeros((dt.n_teams, 2, dt.n_teams))\n",
    "            x = torch.ones(dt.n_teams).reshape(-1, 1)\n",
    "\n",
    "            edge_time = np.empty((dt.n_teams, dt.n_teams))\n",
    "            edge_time[:] = None\n",
    "\n",
    "            node_time = np.zeros(dt.n_teams)\n",
    "\n",
    "            won = data_test[data_test['result'] == \"W\"].shape[0]\n",
    "            lost = data_test[data_test['result'] == \"L\"].shape[0]\n",
    "            draw = data_test[data_test['result'] == \"D\"].shape[0]\n",
    "\n",
    "            data = Data(\n",
    "                edge_index=torch.tensor([]).reshape(2,-1).long(),\n",
    "                edge_weight=torch.tensor([]),\n",
    "                matches=data_train,\n",
    "                n_teams=n_teams,\n",
    "                win_lose_network=win_lose_network,\n",
    "                node_time=node_time,\n",
    "                node_weight=None,\n",
    "                edge_time=edge_time,\n",
    "                data_val=data_val,\n",
    "                data_test=data_test,\n",
    "                data_test_final=data_test_final,\n",
    "                curr_time=0,\n",
    "                N=dt.N,\n",
    "                baseline=max(won, lost, draw),\n",
    "                train_loss=[],\n",
    "                train_accuracy=[],\n",
    "                val_loss=[],\n",
    "                val_accuracy=[],\n",
    "                teams_enc=teams_enc\n",
    "            )\n",
    "            data_list.append(data)\n",
    "\n",
    "        return data_list\n",
    "\t\t\n",
    "def update_edge_index(data):\n",
    "    \"\"\"\n",
    "    Update the edge indeces\n",
    "    :param data: a Dataset instance associated with the model that contains the necessary data for training and the\n",
    "        metadata\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data.edge_index = torch.tensor(np.where(~np.isnan(data.edge_time)))\n",
    "\n",
    "\n",
    "def update_edge_time(data, home, away, result):\n",
    "    \"\"\"\n",
    "    Updating the time of the recent matches between the teams\n",
    "    :param data: a Dataset instance associated with the model that contains the necessary data for training and the\n",
    "        metadata\n",
    "    :param home: the label encoded names of the home teams\n",
    "    :param away: the label encoded names of the away teams\n",
    "    :param result: the outcomes of the matches\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    winning_team = np.array([]).astype('int64')\n",
    "    losing_team = np.array([]).astype('int64')\n",
    "\n",
    "    # home won\n",
    "    winning_team = np.append(winning_team, home[np.where(result == 2)[0]])\n",
    "    losing_team = np.append(losing_team, away[np.where(result == 2)[0]])\n",
    "    # away won\n",
    "    winning_team = np.append(winning_team, away[np.where(result == 0)[0]])\n",
    "    losing_team = np.append(losing_team, home[np.where(result == 0)[0]])\n",
    "    # draw\n",
    "    winning_team = np.append(winning_team, home[np.where(result == 1)[0]])\n",
    "    winning_team = np.append(winning_team, away[np.where(result == 1)[0]])\n",
    "    losing_team = np.append(losing_team, away[np.where(result == 1)[0]])\n",
    "    losing_team = np.append(losing_team, home[np.where(result == 1)[0]])\n",
    "\n",
    "    data.edge_time[losing_team, winning_team] = int(data.curr_time)\n",
    "\n",
    "\n",
    "def calculate_edge_weight(data, time_weighing=\"linear\"):\n",
    "    \"\"\"\n",
    "    Compute the edge weight based on the recency of the last match between the teams\n",
    "    :param data: a Dataset instance associated with the model that contains the necessary data for training and the\n",
    "        metadata\n",
    "    :param time_weighing: the type of weighing: linear or exponential\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if len(data.edge_index) > 0:\n",
    "        from_nodes = data.edge_index[0].numpy()\n",
    "        to_nodes = data.edge_index[1].numpy()\n",
    "\n",
    "        prev_edge_time = data.edge_time[from_nodes, to_nodes]\n",
    "        prev_edge_time[np.isnan(prev_edge_time)] = int(data.curr_time)\n",
    "\n",
    "        if time_weighing == \"linear\":\n",
    "            data.edge_weight = torch.tensor(1 - ((int(data.curr_time) - prev_edge_time) / data.N)).reshape(-1, ).float()\n",
    "        elif time_weighing == \"exponential\":\n",
    "            data.edge_weight = torch.tensor(np.exp( - int(data.curr_time) - prev_edge_time)).reshape(-1, ).float()\n",
    "    else:\n",
    "        data.edge_weight = torch.tensor([])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "log_base = 1.5\n",
    "val_batches = 72\n",
    "target_dim = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def continuous_evaluation(data: Data, model, epochs=100, lr=0.001, lr_discount=0.2, batch_size=9, mode=\"val\"):\n",
    "    \"\"\"\n",
    "    A gateway function for starting the training, validation and testing of the provided model using continuous\n",
    "    evaluation\n",
    "    :param data: a Dataset instance associated with the model that contains the necessary data for training and the\n",
    "        metadata\n",
    "    :param model: the model\n",
    "    :param epochs: the number of epochs\n",
    "    :param lr: the learning rate\n",
    "    :param lr_discount: the learning rate discount if the adaptable learning rate is used\n",
    "    :param batch_size: size of batches in which the model is trained\n",
    "    :param mode: mode in which the function is used: \"val\" for validation, \"test\" for testing\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"Continuous evaluation\")\n",
    "    train_function = train_cont\n",
    "    test_function = test_cont\n",
    "\n",
    "    if mode == \"val\":\n",
    "        print(f\"matches:{data.matches}\")\n",
    "        print(f\"data_val:{data.data_val}\")\n",
    "       # matches = data.matches.append(data.data_val, ignore_index=True)\n",
    "        matches = pd.concat([data.matches,data.data_val])\n",
    "    else:\n",
    "        matches = data.data_test\n",
    "        test_acc = []\n",
    "        global val_batches\n",
    "        val_batches = 1\n",
    "\n",
    "    for i in range(0, matches.shape[0], batch_size):\n",
    "        test_function(data, model, matches.iloc[i:i + val_batches * batch_size])\n",
    "        train_start_point = max(0, i - 40 * batch_size)\n",
    "        data.curr_time = train_start_point\n",
    "        train_function(data,model,\n",
    "                       # matches.head(i + batch_size),\n",
    "                       matches.iloc[train_start_point:i + batch_size],\n",
    "                       # epochs,\n",
    "                       epochs + int(math.log(i + 1, log_base)),\n",
    "                       # lr * (1 - lr_discount) ** int(i / batch_size / 50),\n",
    "                       lr,\n",
    "                       batch_size)\n",
    "        print(\"T:{}, train_loss:{:.5f}, train_acc:{:.5f}, val_loss={:.5f}, val_acc={:.5f}\"\n",
    "              .format(int(i / batch_size),\n",
    "                      data.train_loss[-1],\n",
    "                      data.train_accuracy[-1],\n",
    "                      data.val_loss[-1],\n",
    "                      data.val_accuracy[-1]))\n",
    "        if mode == \"test\":\n",
    "            test_acc.append(data.val_accuracy[-1])\n",
    "\n",
    "    val_acc = data.val_accuracy[len(data.val_accuracy) - val_batches:]\n",
    "    data.val_acc = sum(val_acc) / len(val_acc)\n",
    "\n",
    "    if mode == \"test\":\n",
    "        print(sum(test_acc) / len(test_acc))\n",
    "    else:\n",
    "        print(data.val_acc)\n",
    "\n",
    "\n",
    "def train_cont(data: Data, model: torch.nn.Module, matches,\n",
    "               epochs:int = 100, lr: int = 0.0001, batch_size:int = 9, print_info: bool = False):\n",
    "    \"\"\"\n",
    "    A function for training the provided model with the provided matches using continuous evaluation\n",
    "    :param data: a Dataset instance associated with the model that contains the necessary data for training and the\n",
    "        metadata\n",
    "    :param model: the model\n",
    "    :param matches: the data set\n",
    "    :param epochs: the number of epochs\n",
    "    :param lr: the learning rate\n",
    "    :param batch_size: size of batches in which the model is trained\n",
    "    :param print_info: a binary flag that indicates if the information about the training should be printed out to the\n",
    "        terminal\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    criterion = nn.NLLLoss()  # weight=torch.tensor([1.6,1.95,1])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    running_loss = []\n",
    "    running_accuracy = []\n",
    "    home_win = 0\n",
    "    for epoch in range(epochs):\n",
    "        acc = 0\n",
    "        loss_value = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        for j in range(0, matches.shape[0], batch_size):\n",
    "            home, away, result = torch.from_numpy(matches.iloc[j:j + batch_size]['home_team'].values.astype('int64')), \\\n",
    "                                 torch.from_numpy(matches.iloc[j:j + batch_size]['away_team'].values.astype('int64')), \\\n",
    "                                 torch.from_numpy(\n",
    "                                     matches.iloc[j:j + batch_size]['lwd'].values.astype('int64').reshape(-1, ))\n",
    "            home_win += (result == 2).sum().item()\n",
    "            # label = torch.zeros(result.shape[0], target_dim).scatter_(1, torch.tensor(result), 1)  # one-hot label for loss\n",
    "            outputs = model(data, home, away)\n",
    "            # loss = criterion(outputs, label.to(torch.float))\n",
    "            loss = criterion(outputs, result)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_value += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = int((predicted == result).sum().item())\n",
    "            running_accuracy.append(correct)\n",
    "            acc += correct\n",
    "\n",
    "            update_edge_time(data, home, away, result)\n",
    "            update_edge_index(data)\n",
    "            calculate_edge_weight(data)\n",
    "            data.curr_time += 1\n",
    "\n",
    "        if print_info:\n",
    "            print(\"Epoch:{}, train_loss:{:.5f}, train_acc:{:.5f}\"\n",
    "                  .format(epoch, loss_value, acc / (matches.shape[0])))\n",
    "\n",
    "        data.curr_time -= math.ceil(matches.shape[0] / batch_size)  # probably is safe to be set to 0 each epoch\n",
    "        running_loss.append(loss_value)\n",
    "        # if epoch % 50 == 49:\n",
    "        #     for param_group in optimizer.param_groups:\n",
    "        #         param_group['lr'] *= 0.8\n",
    "    # print(home_win/(matches.shape[0] * epochs))\n",
    "    data.train_loss.append(sum(running_loss) / ((matches.shape[0] / batch_size) * epochs))\n",
    "    data.train_accuracy.append(sum(running_accuracy) / (matches.shape[0] * epochs))\n",
    "\n",
    "\n",
    "def test_cont(data: Data, model: torch.nn.Module, matches, mode: str = \"val\"):\n",
    "    \"\"\"\n",
    "    A function for testing the provided model on the provided matches using continuous evaluation\n",
    "    :param data: a Dataset instance associated with the model that contains the necessary data for training and the\n",
    "        metadata\n",
    "    :param model: the model\n",
    "    :param matches: the data set\n",
    "    :param mode: mode in which the testing function is used: \"val\" for validation, \"test\" for testing\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    criterion = nn.NLLLoss()  # weight=torch.tensor([1.6,1.95,1])\n",
    "\n",
    "    predicted, label, outputs = get_predictions(data, model, matches)\n",
    "\n",
    "    loss = criterion(outputs, label).item()\n",
    "\n",
    "    correct = int((predicted == label).sum().item())\n",
    "    if mode == \"test\":\n",
    "        data.test_accuracy = float(correct) / matches.shape[0]\n",
    "    else:\n",
    "        data.val_accuracy.append(float(correct) / matches.shape[0])\n",
    "        data.val_loss.append(loss)\n",
    "        \n",
    "        \n",
    "def get_predictions(data: Data, model: torch.nn.Module, matches) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Compute the predictions for the provided matches using provided model\n",
    "    :param data: a Dataset instance associated with the model that contains the necessary data for training and the\n",
    "        metadata\n",
    "    :param model: the model\n",
    "    :param matches: the data set\n",
    "    :return: Tensors of predictions for each match, a ground truth label and the probabilities\n",
    "    \"\"\"\n",
    "    outputs, label = get_probabilities(data, model, matches)\n",
    "    _, predicted = torch.max(torch.exp(outputs.data), 1)\n",
    "    return predicted, label, outputs\n",
    "\n",
    "\n",
    "def get_probabilities(data, model, matches):\n",
    "    model.eval()\n",
    "    home, away, label = torch.from_numpy(matches['home_team'].values.astype('int64')), \\\n",
    "                        torch.from_numpy(matches['away_team'].values.astype('int64')), \\\n",
    "                        torch.from_numpy(matches['lwd'].values.astype('int64').reshape(-1, ))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data, home, away)\n",
    "    model.train()\n",
    "    return outputs, label\n",
    "\n",
    "\n",
    "def get_rps(data: Data, model: torch.nn.Module, matches) -> float:\n",
    "    \"\"\"\n",
    "    Computation of PRS score for a provided model on provided data\n",
    "    :param data: a Dataset instance associated with the model that contains the necessary data for training and the\n",
    "        metadata\n",
    "    :param model: the model\n",
    "    :param matches: the data set\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    outputs, label = get_probabilities(data, model, matches)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    o_h_label = torch.zeros(label.shape[0], target_dim).scatter_(1, label.reshape(-1, 1), 1)  # one-hot label for loss\n",
    "    outputs = torch.exp(outputs)\n",
    "    sub = torch.zeros((label.shape[0]))\n",
    "    for i in range(target_dim):\n",
    "        sub += torch.pow(torch.sum(outputs[:, :i + 1], 1) - torch.sum(o_h_label[:, :i + 1], 1), 2)\n",
    "    rps = sub / (target_dim - 1)\n",
    "    return rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbe2a2f1-1381-45ec-b2e0-82b3ce047faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 84.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train data points: 1016, Won: 42.81496062992126%, Lost: 33.36614173228347%, Draw: 23.818897637795274%\n",
      "Total val data points: 127, Won: 42.51968503937008%, Lost: 37.00787401574803%, Draw: 20.47244094488189%\n",
      "Total test data points: 128, Won: 46.09375%, Lost: 32.03125%, Draw: 21.875%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filename='./data/NHL.csv'\n",
    "dataset = Dataset(filename=filename)\n",
    "data_list = dataset.process() # load and process all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a39a57d-080f-4100-b00a-71f910695176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN model, data {} 0\n",
      "Continuous evaluation\n",
      "matches:      year league      time home_team away_team home_score away_score  \\\n",
      "0     2017    NHL  04-10-17        30        26          2          7   \n",
      "1     2017    NHL  05-10-17        10        14          4          2   \n",
      "2     2017    NHL  05-10-17        20        29          4          4   \n",
      "3     2017    NHL  05-10-17         2        16          4          3   \n",
      "4     2017    NHL  05-10-17         3        15          2          2   \n",
      "...    ...    ...       ...       ...       ...        ...        ...   \n",
      "1011  2017    NHL  05-03-18         5        30          2          3   \n",
      "1012  2017    NHL  05-03-18        14        10          4          1   \n",
      "1013  2017    NHL  06-03-18        27        18          3          3   \n",
      "1014  2017    NHL  06-03-18        11         1          3          3   \n",
      "1015  2017    NHL  06-03-18         9        20          2          2   \n",
      "\n",
      "     difference_score result country home_shots away_shots home_hits  \\\n",
      "0                  -5      L     NHL         37         31        18   \n",
      "1                   2      W     NHL         31         39        13   \n",
      "2                   0      D     NHL         32         28        28   \n",
      "3                   1      W     NHL         32         29        23   \n",
      "4                   0      D     NHL         45         40        20   \n",
      "...               ...    ...     ...        ...        ...       ...   \n",
      "1011               -1      L     NHL         35         23        24   \n",
      "1012                3      W     NHL         27         29        11   \n",
      "1013                0      D     NHL         23         34        22   \n",
      "1014                0      D     NHL         36         35        33   \n",
      "1015                0      D     NHL         33         30        22   \n",
      "\n",
      "     away_hits lwd  \n",
      "0           16   0  \n",
      "1           19   2  \n",
      "2           25   1  \n",
      "3           25   2  \n",
      "4           17   1  \n",
      "...        ...  ..  \n",
      "1011        31   0  \n",
      "1012        17   2  \n",
      "1013        13   1  \n",
      "1014        30   1  \n",
      "1015        10   1  \n",
      "\n",
      "[1016 rows x 15 columns]\n",
      "data_val:     year league      time home_team away_team home_score away_score  \\\n",
      "0    2017    NHL  06-03-18         3        26          5          3   \n",
      "1    2017    NHL  06-03-18        22         4          3          3   \n",
      "2    2017    NHL  07-03-18         0        29          4          0   \n",
      "3    2017    NHL  07-03-18         6         7          1          1   \n",
      "4    2017    NHL  07-03-18        14         5          6          2   \n",
      "..    ...    ...       ...       ...       ...        ...        ...   \n",
      "122  2017    NHL  22-03-18         4         0          0          4   \n",
      "123  2017    NHL  22-03-18        24         2          1          1   \n",
      "124  2017    NHL  23-03-18         3        15          0          3   \n",
      "125  2017    NHL  23-03-18        22        17          3          3   \n",
      "126  2017    NHL  23-03-18        23        28          1          1   \n",
      "\n",
      "    difference_score result country home_shots away_shots home_hits away_hits  \\\n",
      "0                  2      W     NHL         24         41        20        23   \n",
      "1                  0      D     NHL         32         38        20        27   \n",
      "2                  4      W     NHL         18         36        23        22   \n",
      "3                  0      D     NHL         27         34        19        35   \n",
      "4                  4      W     NHL         31         31         8         6   \n",
      "..               ...    ...     ...        ...        ...       ...       ...   \n",
      "122               -4      L     NHL         29         16        37        14   \n",
      "123                0      D     NHL         20         22        46        24   \n",
      "124               -3      L     NHL         35         24        28        19   \n",
      "125                0      D     NHL         43         34        20        37   \n",
      "126                0      D     NHL         44         25        16        25   \n",
      "\n",
      "    lwd  \n",
      "0     2  \n",
      "1     1  \n",
      "2     2  \n",
      "3     1  \n",
      "4     2  \n",
      "..   ..  \n",
      "122   0  \n",
      "123   1  \n",
      "124   0  \n",
      "125   1  \n",
      "126   1  \n",
      "\n",
      "[127 rows x 15 columns]\n",
      "T:0, train_loss:2.07891, train_acc:0.36667, val_loss=1.37092, val_acc=0.24846\n",
      "T:1, train_loss:1.06790, train_acc:0.45238, val_loss=1.09426, val_acc=0.39969\n",
      "T:2, train_loss:1.04485, train_acc:0.49449, val_loss=1.08975, val_acc=0.42747\n",
      "T:3, train_loss:1.06107, train_acc:0.49635, val_loss=1.10661, val_acc=0.41975\n",
      "T:4, train_loss:1.10981, train_acc:0.42456, val_loss=1.09353, val_acc=0.41975\n",
      "T:5, train_loss:1.05339, train_acc:0.46391, val_loss=1.08201, val_acc=0.42438\n",
      "T:6, train_loss:1.05610, train_acc:0.47416, val_loss=1.08731, val_acc=0.41667\n",
      "T:7, train_loss:1.04297, train_acc:0.47708, val_loss=1.08420, val_acc=0.41512\n",
      "T:8, train_loss:1.07108, train_acc:0.45833, val_loss=1.09542, val_acc=0.41358\n",
      "T:9, train_loss:1.06836, train_acc:0.46083, val_loss=1.09667, val_acc=0.41512\n",
      "T:10, train_loss:1.05875, train_acc:0.45775, val_loss=1.08237, val_acc=0.41667\n",
      "T:11, train_loss:1.07826, train_acc:0.42344, val_loss=1.08221, val_acc=0.41512\n",
      "T:12, train_loss:1.06036, train_acc:0.44736, val_loss=1.07880, val_acc=0.41667\n",
      "T:13, train_loss:1.05655, train_acc:0.45490, val_loss=1.07746, val_acc=0.41049\n",
      "T:14, train_loss:1.06356, train_acc:0.43595, val_loss=1.07604, val_acc=0.41049\n",
      "T:15, train_loss:1.04808, train_acc:0.45453, val_loss=1.07049, val_acc=0.41204\n",
      "T:16, train_loss:1.04721, train_acc:0.45954, val_loss=1.07353, val_acc=0.40895\n",
      "T:17, train_loss:1.04638, train_acc:0.45297, val_loss=1.07035, val_acc=0.40895\n",
      "T:18, train_loss:1.04274, train_acc:0.45322, val_loss=1.07407, val_acc=0.41512\n",
      "T:19, train_loss:1.03934, train_acc:0.46151, val_loss=1.06826, val_acc=0.41667\n",
      "T:20, train_loss:1.03386, train_acc:0.46208, val_loss=1.07539, val_acc=0.42438\n",
      "T:21, train_loss:1.01813, train_acc:0.47932, val_loss=1.07884, val_acc=0.48302\n",
      "T:22, train_loss:1.01799, train_acc:0.48893, val_loss=1.10309, val_acc=0.42593\n",
      "T:23, train_loss:1.02152, train_acc:0.48407, val_loss=1.11467, val_acc=0.45679\n",
      "T:24, train_loss:1.03333, train_acc:0.47711, val_loss=1.12807, val_acc=0.43364\n",
      "T:25, train_loss:1.02421, train_acc:0.48310, val_loss=1.12316, val_acc=0.39969\n",
      "T:26, train_loss:1.02812, train_acc:0.48665, val_loss=1.15703, val_acc=0.42747\n",
      "T:27, train_loss:1.02426, train_acc:0.49068, val_loss=1.14593, val_acc=0.43519\n",
      "T:28, train_loss:1.02543, train_acc:0.48508, val_loss=1.16531, val_acc=0.42747\n",
      "T:29, train_loss:1.02017, train_acc:0.49078, val_loss=1.13032, val_acc=0.41667\n",
      "T:30, train_loss:1.02204, train_acc:0.48796, val_loss=1.14203, val_acc=0.41512\n",
      "T:31, train_loss:1.01419, train_acc:0.49362, val_loss=1.16749, val_acc=0.43056\n",
      "T:32, train_loss:1.00919, train_acc:0.50004, val_loss=1.17333, val_acc=0.42593\n",
      "T:33, train_loss:1.00267, train_acc:0.49599, val_loss=1.21385, val_acc=0.41204\n",
      "T:34, train_loss:1.00767, train_acc:0.50354, val_loss=1.19876, val_acc=0.41667\n",
      "T:35, train_loss:1.00265, train_acc:0.50512, val_loss=1.25027, val_acc=0.41821\n",
      "T:36, train_loss:0.99572, train_acc:0.50471, val_loss=1.24787, val_acc=0.41512\n",
      "T:37, train_loss:1.00400, train_acc:0.51110, val_loss=1.26935, val_acc=0.42284\n",
      "T:38, train_loss:1.01082, train_acc:0.51023, val_loss=1.25973, val_acc=0.43673\n",
      "T:39, train_loss:1.02177, train_acc:0.51319, val_loss=1.29659, val_acc=0.42747\n",
      "T:40, train_loss:1.02200, train_acc:0.50776, val_loss=1.26441, val_acc=0.42130\n",
      "T:41, train_loss:1.01999, train_acc:0.52063, val_loss=1.23748, val_acc=0.43210\n",
      "T:42, train_loss:1.03185, train_acc:0.50795, val_loss=1.25819, val_acc=0.42747\n",
      "T:43, train_loss:1.02394, train_acc:0.51718, val_loss=1.25106, val_acc=0.42747\n",
      "T:44, train_loss:1.02896, train_acc:0.52156, val_loss=1.28227, val_acc=0.42593\n",
      "T:45, train_loss:1.03254, train_acc:0.51644, val_loss=1.24196, val_acc=0.43827\n",
      "T:46, train_loss:1.02764, train_acc:0.52150, val_loss=1.27694, val_acc=0.43981\n",
      "T:47, train_loss:1.01283, train_acc:0.52889, val_loss=1.31051, val_acc=0.42284\n",
      "T:48, train_loss:1.00001, train_acc:0.53030, val_loss=1.33737, val_acc=0.42901\n",
      "T:49, train_loss:0.98066, train_acc:0.54080, val_loss=1.34530, val_acc=0.42438\n",
      "T:50, train_loss:0.97024, train_acc:0.54857, val_loss=1.38974, val_acc=0.42284\n",
      "T:51, train_loss:0.95624, train_acc:0.55194, val_loss=1.34818, val_acc=0.41667\n",
      "T:52, train_loss:0.95573, train_acc:0.54664, val_loss=1.34547, val_acc=0.39506\n",
      "T:53, train_loss:0.94963, train_acc:0.56393, val_loss=1.40755, val_acc=0.41667\n",
      "T:54, train_loss:0.94504, train_acc:0.56658, val_loss=1.36605, val_acc=0.39815\n",
      "T:55, train_loss:0.94250, train_acc:0.57151, val_loss=1.40021, val_acc=0.41049\n",
      "T:56, train_loss:0.95657, train_acc:0.57332, val_loss=1.40461, val_acc=0.39437\n",
      "T:57, train_loss:0.95229, train_acc:0.57880, val_loss=1.43317, val_acc=0.39048\n",
      "T:58, train_loss:0.97793, train_acc:0.58302, val_loss=1.48182, val_acc=0.39452\n",
      "T:59, train_loss:0.95836, train_acc:0.59482, val_loss=1.43734, val_acc=0.38562\n",
      "T:60, train_loss:0.94604, train_acc:0.60909, val_loss=1.48367, val_acc=0.37977\n",
      "T:61, train_loss:0.94293, train_acc:0.61162, val_loss=1.46753, val_acc=0.36532\n",
      "T:62, train_loss:0.93182, train_acc:0.61271, val_loss=1.50878, val_acc=0.33846\n",
      "T:63, train_loss:0.91808, train_acc:0.61475, val_loss=1.49580, val_acc=0.36632\n",
      "T:64, train_loss:0.91483, train_acc:0.61734, val_loss=1.47254, val_acc=0.37037\n",
      "T:65, train_loss:0.89903, train_acc:0.62463, val_loss=1.44698, val_acc=0.39068\n",
      "T:66, train_loss:0.88629, train_acc:0.62608, val_loss=1.46522, val_acc=0.38434\n",
      "T:67, train_loss:0.88668, train_acc:0.62036, val_loss=1.47318, val_acc=0.38889\n",
      "T:68, train_loss:0.90164, train_acc:0.61168, val_loss=1.58079, val_acc=0.39171\n",
      "T:69, train_loss:0.91679, train_acc:0.62180, val_loss=1.46817, val_acc=0.40421\n",
      "T:70, train_loss:0.91172, train_acc:0.61795, val_loss=1.41428, val_acc=0.41326\n",
      "T:71, train_loss:0.89361, train_acc:0.62662, val_loss=1.44034, val_acc=0.40873\n",
      "T:72, train_loss:0.88577, train_acc:0.63186, val_loss=1.55503, val_acc=0.40000\n",
      "T:73, train_loss:0.87754, train_acc:0.63297, val_loss=1.39201, val_acc=0.41564\n",
      "T:74, train_loss:0.87914, train_acc:0.64110, val_loss=1.49890, val_acc=0.41300\n",
      "T:75, train_loss:0.88104, train_acc:0.65082, val_loss=1.58874, val_acc=0.39316\n",
      "T:76, train_loss:0.87620, train_acc:0.64823, val_loss=1.53271, val_acc=0.39216\n",
      "T:77, train_loss:0.86314, train_acc:0.66025, val_loss=1.63721, val_acc=0.39556\n",
      "T:78, train_loss:0.87297, train_acc:0.65865, val_loss=1.64822, val_acc=0.37188\n",
      "T:79, train_loss:0.85355, train_acc:0.66773, val_loss=1.62150, val_acc=0.39120\n",
      "T:80, train_loss:0.84526, train_acc:0.67002, val_loss=1.69432, val_acc=0.37825\n",
      "T:81, train_loss:0.86561, train_acc:0.66543, val_loss=1.76326, val_acc=0.37198\n",
      "T:82, train_loss:0.87283, train_acc:0.66378, val_loss=1.66722, val_acc=0.40494\n",
      "T:83, train_loss:0.86804, train_acc:0.66095, val_loss=1.60267, val_acc=0.40404\n",
      "T:84, train_loss:0.88226, train_acc:0.65712, val_loss=1.65427, val_acc=0.38760\n",
      "T:85, train_loss:0.88586, train_acc:0.66184, val_loss=1.64136, val_acc=0.37566\n",
      "T:86, train_loss:0.90941, train_acc:0.65553, val_loss=1.75785, val_acc=0.38753\n",
      "T:87, train_loss:0.89940, train_acc:0.65647, val_loss=1.67971, val_acc=0.37222\n",
      "T:88, train_loss:0.90063, train_acc:0.66001, val_loss=1.59780, val_acc=0.39601\n",
      "T:89, train_loss:0.90359, train_acc:0.66166, val_loss=1.64139, val_acc=0.40351\n",
      "T:90, train_loss:0.90332, train_acc:0.65918, val_loss=1.66788, val_acc=0.40841\n",
      "T:91, train_loss:0.90997, train_acc:0.65182, val_loss=1.57783, val_acc=0.39198\n",
      "T:92, train_loss:0.91108, train_acc:0.65141, val_loss=1.58667, val_acc=0.35873\n",
      "T:93, train_loss:0.89382, train_acc:0.65247, val_loss=1.55779, val_acc=0.39216\n",
      "T:94, train_loss:0.89782, train_acc:0.64328, val_loss=1.55930, val_acc=0.39394\n",
      "T:95, train_loss:0.87447, train_acc:0.65471, val_loss=1.46042, val_acc=0.42361\n",
      "T:96, train_loss:0.88319, train_acc:0.65182, val_loss=1.48247, val_acc=0.43011\n",
      "T:97, train_loss:0.88316, train_acc:0.66019, val_loss=1.42637, val_acc=0.45556\n",
      "T:98, train_loss:0.88072, train_acc:0.66443, val_loss=1.39822, val_acc=0.45977\n",
      "T:99, train_loss:0.86454, train_acc:0.66690, val_loss=1.39317, val_acc=0.45635\n",
      "T:100, train_loss:0.84941, train_acc:0.67368, val_loss=1.41390, val_acc=0.44033\n",
      "T:101, train_loss:0.83788, train_acc:0.67427, val_loss=1.45354, val_acc=0.43590\n",
      "T:102, train_loss:0.83091, train_acc:0.67651, val_loss=1.52398, val_acc=0.42222\n",
      "T:103, train_loss:0.82232, train_acc:0.67450, val_loss=1.53819, val_acc=0.42130\n",
      "T:104, train_loss:0.82000, train_acc:0.67344, val_loss=1.59098, val_acc=0.41063\n",
      "T:105, train_loss:0.85634, train_acc:0.66172, val_loss=1.61634, val_acc=0.40909\n",
      "T:106, train_loss:0.85144, train_acc:0.67268, val_loss=1.63183, val_acc=0.40741\n",
      "T:107, train_loss:0.86090, train_acc:0.67303, val_loss=1.68703, val_acc=0.42222\n",
      "T:108, train_loss:0.88709, train_acc:0.66997, val_loss=1.75387, val_acc=0.40936\n",
      "T:109, train_loss:0.87807, train_acc:0.67002, val_loss=1.73359, val_acc=0.40123\n",
      "T:110, train_loss:0.86876, train_acc:0.66938, val_loss=1.61743, val_acc=0.41176\n",
      "T:111, train_loss:0.86095, train_acc:0.66874, val_loss=1.60562, val_acc=0.43750\n",
      "T:112, train_loss:0.86515, train_acc:0.66684, val_loss=1.61439, val_acc=0.45185\n",
      "T:113, train_loss:0.86528, train_acc:0.65882, val_loss=1.57099, val_acc=0.41270\n",
      "T:114, train_loss:0.85052, train_acc:0.66845, val_loss=1.56402, val_acc=0.43590\n",
      "T:115, train_loss:0.82228, train_acc:0.67641, val_loss=1.50827, val_acc=0.44444\n",
      "T:116, train_loss:0.80866, train_acc:0.68864, val_loss=1.59503, val_acc=0.39394\n",
      "T:117, train_loss:0.81371, train_acc:0.68823, val_loss=1.68256, val_acc=0.38889\n",
      "T:118, train_loss:0.79456, train_acc:0.69342, val_loss=1.67486, val_acc=0.39506\n",
      "T:119, train_loss:0.80771, train_acc:0.68310, val_loss=1.73468, val_acc=0.37500\n",
      "T:120, train_loss:0.80041, train_acc:0.68817, val_loss=1.63056, val_acc=0.39683\n",
      "T:121, train_loss:0.77607, train_acc:0.69803, val_loss=1.64215, val_acc=0.42593\n",
      "T:122, train_loss:0.78111, train_acc:0.70103, val_loss=1.75601, val_acc=0.44444\n",
      "T:123, train_loss:0.76696, train_acc:0.70357, val_loss=1.69015, val_acc=0.44444\n",
      "T:124, train_loss:0.77687, train_acc:0.70167, val_loss=1.98839, val_acc=0.51852\n",
      "T:125, train_loss:0.77381, train_acc:0.70484, val_loss=2.15635, val_acc=0.44444\n",
      "T:126, train_loss:0.80769, train_acc:0.70564, val_loss=3.17076, val_acc=0.44444\n",
      "0.4062258890240524\n",
      "accuracy on testing data is: 0.421875\n",
      "rps is below\n",
      "0.3157758414745331\n"
     ]
    }
   ],
   "source": [
    "def run_gnn_cont(data_list, dir_prefix=\"../\", lr=0.0001, exp_num=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Training a GNN model using continuous evaluation. The model is then saved into pickle.\n",
    "    :param filename: the name of the file with the input data\n",
    "    :param dir_prefix: directory prefix for model saving\n",
    "    :param lr: a learning rate for training\n",
    "    :param exp_num: experiment number\n",
    "    :param kwargs: additional parameters for the model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    epochs = [30] # number of initial epochs\n",
    "    test_acc = []\n",
    "    val_acc = []\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    n_all_teams = 0\n",
    "    for data in data_list:\n",
    "        n_all_teams += data.n_teams\n",
    "    model = GNNModel_from_paper(n_all_teams, **kwargs)\n",
    "\n",
    "    for i, data in enumerate(data_list):\n",
    "        print(\"GNN model, data {}\", i)\n",
    "        continuous_evaluation(data, model, epochs[0],lr=lr, batch_size=9)\n",
    "        test_cont(data, model, data.data_test, \"test\")\n",
    "        print(\"accuracy on testing data is: {}\".format(data.test_accuracy))\n",
    "        rps = get_rps(data, model, data.data_test)\n",
    "        print(\"rps is below\")\n",
    "        print(torch.mean(rps).item())\n",
    "        #print(\"accuracy on validation data is: {}\".format(data.val_accuracy))\n",
    "        #file = outfile.format(pickle_dir.format(dir_prefix), i, exp_num, \"pickle\")\n",
    "        data_to_save = {\"data\": data, \"model\": model, \"epochs\": epochs}\n",
    "        #save_to_pickle(file, data_to_save)\n",
    "        test_acc.append(data.test_accuracy)\n",
    "        val_acc.append(data.val_acc)\n",
    "        train_loss.append(data.train_loss)\n",
    "        val_loss.append(data.val_loss)\n",
    "    \n",
    "    test_accuracy = sum(test_acc) / len(test_acc)\n",
    "    val_accuracy = sum(val_acc) / len(val_acc)\n",
    "    #file = outfile.format(pickle_dir.format(dir_prefix), \"all\", exp_num, \"pickle\")\n",
    "    #data_to_save = {\"test_acc\": test_acc, \"val_acc\": val_acc}\n",
    "    #save_to_pickle(file, data_to_save)\n",
    "    return test_accuracy, val_accuracy,model, dataset\n",
    "\n",
    "test_acc, val_acc, model,dataset = run_gnn_cont(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f658d5a4-a275-4988-b543-8ee50e4430d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for data in data_list:\n",
    "    y_pred, y_true, prob = get_predictions(data, model, data.data_test)\n",
    "    y_pred, y_true = y_pred.numpy().astype('int'), y_true.numpy().astype('int')        \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[2, 1, 0])  # Assuming labels are 2 for \"W\", 1 for \"D\", and 2 for \"L\"\n",
    "\n",
    "    # Visualize the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"W\", \"D\", \"L\"])\n",
    "    disp.plot(cmap='Blues')\n",
    "    fig1 = plt.gcf()\n",
    "    plt.show()\n",
    "    fig1.savefig('cm_gnn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66c46723-a6ef-448c-8afa-82028b65f1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat model, data {} 0\n",
      "Continuous evaluation\n",
      "matches:      year league      time home_team away_team home_score away_score  \\\n",
      "0     2017    NHL  04-10-17        30        26          2          7   \n",
      "1     2017    NHL  05-10-17        10        14          4          2   \n",
      "2     2017    NHL  05-10-17        20        29          4          4   \n",
      "3     2017    NHL  05-10-17         2        16          4          3   \n",
      "4     2017    NHL  05-10-17         3        15          2          2   \n",
      "...    ...    ...       ...       ...       ...        ...        ...   \n",
      "1011  2017    NHL  05-03-18         5        30          2          3   \n",
      "1012  2017    NHL  05-03-18        14        10          4          1   \n",
      "1013  2017    NHL  06-03-18        27        18          3          3   \n",
      "1014  2017    NHL  06-03-18        11         1          3          3   \n",
      "1015  2017    NHL  06-03-18         9        20          2          2   \n",
      "\n",
      "     difference_score result country home_shots away_shots home_hits  \\\n",
      "0                  -5      L     NHL         37         31        18   \n",
      "1                   2      W     NHL         31         39        13   \n",
      "2                   0      D     NHL         32         28        28   \n",
      "3                   1      W     NHL         32         29        23   \n",
      "4                   0      D     NHL         45         40        20   \n",
      "...               ...    ...     ...        ...        ...       ...   \n",
      "1011               -1      L     NHL         35         23        24   \n",
      "1012                3      W     NHL         27         29        11   \n",
      "1013                0      D     NHL         23         34        22   \n",
      "1014                0      D     NHL         36         35        33   \n",
      "1015                0      D     NHL         33         30        22   \n",
      "\n",
      "     away_hits lwd  \n",
      "0           16   0  \n",
      "1           19   2  \n",
      "2           25   1  \n",
      "3           25   2  \n",
      "4           17   1  \n",
      "...        ...  ..  \n",
      "1011        31   0  \n",
      "1012        17   2  \n",
      "1013        13   1  \n",
      "1014        30   1  \n",
      "1015        10   1  \n",
      "\n",
      "[1016 rows x 15 columns]\n",
      "data_val:     year league      time home_team away_team home_score away_score  \\\n",
      "0    2017    NHL  06-03-18         3        26          5          3   \n",
      "1    2017    NHL  06-03-18        22         4          3          3   \n",
      "2    2017    NHL  07-03-18         0        29          4          0   \n",
      "3    2017    NHL  07-03-18         6         7          1          1   \n",
      "4    2017    NHL  07-03-18        14         5          6          2   \n",
      "..    ...    ...       ...       ...       ...        ...        ...   \n",
      "122  2017    NHL  22-03-18         4         0          0          4   \n",
      "123  2017    NHL  22-03-18        24         2          1          1   \n",
      "124  2017    NHL  23-03-18         3        15          0          3   \n",
      "125  2017    NHL  23-03-18        22        17          3          3   \n",
      "126  2017    NHL  23-03-18        23        28          1          1   \n",
      "\n",
      "    difference_score result country home_shots away_shots home_hits away_hits  \\\n",
      "0                  2      W     NHL         24         41        20        23   \n",
      "1                  0      D     NHL         32         38        20        27   \n",
      "2                  4      W     NHL         18         36        23        22   \n",
      "3                  0      D     NHL         27         34        19        35   \n",
      "4                  4      W     NHL         31         31         8         6   \n",
      "..               ...    ...     ...        ...        ...       ...       ...   \n",
      "122               -4      L     NHL         29         16        37        14   \n",
      "123                0      D     NHL         20         22        46        24   \n",
      "124               -3      L     NHL         35         24        28        19   \n",
      "125                0      D     NHL         43         34        20        37   \n",
      "126                0      D     NHL         44         25        16        25   \n",
      "\n",
      "    lwd  \n",
      "0     2  \n",
      "1     1  \n",
      "2     2  \n",
      "3     1  \n",
      "4     2  \n",
      "..   ..  \n",
      "122   0  \n",
      "123   1  \n",
      "124   0  \n",
      "125   1  \n",
      "126   1  \n",
      "\n",
      "[127 rows x 15 columns]\n",
      "T:0, train_loss:1.11630, train_acc:0.32963, val_loss=1.07817, val_acc=0.43364\n",
      "T:1, train_loss:1.03537, train_acc:0.54603, val_loss=1.07823, val_acc=0.43364\n",
      "T:2, train_loss:1.02267, train_acc:0.58158, val_loss=1.08057, val_acc=0.42747\n",
      "T:3, train_loss:1.04431, train_acc:0.51754, val_loss=1.08337, val_acc=0.41975\n",
      "T:4, train_loss:1.07621, train_acc:0.44152, val_loss=1.08344, val_acc=0.41975\n",
      "T:5, train_loss:1.05314, train_acc:0.49478, val_loss=1.08167, val_acc=0.42438\n",
      "T:6, train_loss:1.05805, train_acc:0.48759, val_loss=1.08452, val_acc=0.41667\n",
      "T:7, train_loss:1.05566, train_acc:0.49132, val_loss=1.08505, val_acc=0.41512\n",
      "T:8, train_loss:1.06555, train_acc:0.46698, val_loss=1.08565, val_acc=0.41358\n",
      "T:9, train_loss:1.06693, train_acc:0.46306, val_loss=1.08506, val_acc=0.41512\n",
      "T:10, train_loss:1.06724, train_acc:0.45997, val_loss=1.08445, val_acc=0.41667\n",
      "T:11, train_loss:1.08393, train_acc:0.42096, val_loss=1.08501, val_acc=0.41512\n",
      "T:12, train_loss:1.07318, train_acc:0.44757, val_loss=1.08442, val_acc=0.41667\n",
      "T:13, train_loss:1.07289, train_acc:0.44657, val_loss=1.08694, val_acc=0.41049\n",
      "T:14, train_loss:1.07409, train_acc:0.44246, val_loss=1.08694, val_acc=0.41049\n",
      "T:15, train_loss:1.06907, train_acc:0.45453, val_loss=1.08636, val_acc=0.41204\n",
      "T:16, train_loss:1.06666, train_acc:0.45876, val_loss=1.08766, val_acc=0.40895\n",
      "T:17, train_loss:1.06896, train_acc:0.45356, val_loss=1.08768, val_acc=0.40895\n",
      "T:18, train_loss:1.07002, train_acc:0.44862, val_loss=1.08498, val_acc=0.41512\n",
      "T:19, train_loss:1.06553, train_acc:0.45608, val_loss=1.08426, val_acc=0.41667\n",
      "T:20, train_loss:1.06481, train_acc:0.45578, val_loss=1.08620, val_acc=0.41204\n",
      "T:21, train_loss:1.06145, train_acc:0.46020, val_loss=1.08542, val_acc=0.41358\n",
      "T:22, train_loss:1.06430, train_acc:0.45534, val_loss=1.08674, val_acc=0.41049\n",
      "T:23, train_loss:1.06982, train_acc:0.44584, val_loss=1.08510, val_acc=0.41358\n",
      "T:24, train_loss:1.06873, train_acc:0.44217, val_loss=1.08399, val_acc=0.41512\n",
      "T:25, train_loss:1.06554, train_acc:0.44385, val_loss=1.08246, val_acc=0.41821\n",
      "T:26, train_loss:1.06447, train_acc:0.44521, val_loss=1.08144, val_acc=0.41975\n",
      "T:27, train_loss:1.06070, train_acc:0.44684, val_loss=1.07977, val_acc=0.42284\n",
      "T:28, train_loss:1.06477, train_acc:0.43776, val_loss=1.08180, val_acc=0.41821\n",
      "T:29, train_loss:1.06005, train_acc:0.44436, val_loss=1.07932, val_acc=0.42284\n",
      "T:30, train_loss:1.05647, train_acc:0.44753, val_loss=1.08063, val_acc=0.41975\n",
      "T:31, train_loss:1.05158, train_acc:0.46076, val_loss=1.08047, val_acc=0.41512\n",
      "T:32, train_loss:1.04372, train_acc:0.47412, val_loss=1.08169, val_acc=0.41204\n",
      "T:33, train_loss:1.03948, train_acc:0.47839, val_loss=1.08265, val_acc=0.41667\n",
      "T:34, train_loss:1.03468, train_acc:0.48470, val_loss=1.08573, val_acc=0.41204\n",
      "T:35, train_loss:1.02755, train_acc:0.48793, val_loss=1.09060, val_acc=0.40741\n",
      "T:36, train_loss:1.03449, train_acc:0.47864, val_loss=1.09657, val_acc=0.40586\n",
      "T:37, train_loss:1.02937, train_acc:0.48804, val_loss=1.09837, val_acc=0.40432\n",
      "T:38, train_loss:1.03471, train_acc:0.48401, val_loss=1.10127, val_acc=0.41049\n",
      "T:39, train_loss:1.03161, train_acc:0.48220, val_loss=1.10506, val_acc=0.40432\n",
      "T:40, train_loss:1.03297, train_acc:0.48319, val_loss=1.10834, val_acc=0.40586\n",
      "T:41, train_loss:1.03488, train_acc:0.48386, val_loss=1.11136, val_acc=0.40123\n",
      "T:42, train_loss:1.03923, train_acc:0.48596, val_loss=1.11376, val_acc=0.39969\n",
      "T:43, train_loss:1.04076, train_acc:0.47906, val_loss=1.11323, val_acc=0.40586\n",
      "T:44, train_loss:1.03955, train_acc:0.48004, val_loss=1.11023, val_acc=0.41049\n",
      "T:45, train_loss:1.04971, train_acc:0.47980, val_loss=1.10916, val_acc=0.41049\n",
      "T:46, train_loss:1.05900, train_acc:0.46489, val_loss=1.10398, val_acc=0.41204\n",
      "T:47, train_loss:1.06304, train_acc:0.46249, val_loss=1.09847, val_acc=0.41204\n",
      "T:48, train_loss:1.06363, train_acc:0.45787, val_loss=1.09864, val_acc=0.40895\n",
      "T:49, train_loss:1.06324, train_acc:0.45378, val_loss=1.09979, val_acc=0.41204\n",
      "T:50, train_loss:1.06419, train_acc:0.44842, val_loss=1.09710, val_acc=0.41821\n",
      "T:51, train_loss:1.07429, train_acc:0.44222, val_loss=1.09394, val_acc=0.42438\n",
      "T:52, train_loss:1.07437, train_acc:0.44962, val_loss=1.08535, val_acc=0.42747\n",
      "T:53, train_loss:1.06476, train_acc:0.45107, val_loss=1.08308, val_acc=0.42747\n",
      "T:54, train_loss:1.07261, train_acc:0.44499, val_loss=1.08755, val_acc=0.42593\n",
      "T:55, train_loss:1.06740, train_acc:0.44938, val_loss=1.08264, val_acc=0.42747\n",
      "T:56, train_loss:1.06917, train_acc:0.45185, val_loss=1.08242, val_acc=0.43349\n",
      "T:57, train_loss:1.06876, train_acc:0.45137, val_loss=1.08273, val_acc=0.42540\n",
      "T:58, train_loss:1.07200, train_acc:0.44649, val_loss=1.08391, val_acc=0.41868\n",
      "T:59, train_loss:1.07409, train_acc:0.44089, val_loss=1.08065, val_acc=0.41830\n",
      "T:60, train_loss:1.07466, train_acc:0.44336, val_loss=1.07844, val_acc=0.42620\n",
      "T:61, train_loss:1.07424, train_acc:0.44089, val_loss=1.07727, val_acc=0.43266\n",
      "T:62, train_loss:1.07060, train_acc:0.43848, val_loss=1.07610, val_acc=0.43932\n",
      "T:63, train_loss:1.06856, train_acc:0.44101, val_loss=1.07534, val_acc=0.43924\n",
      "T:64, train_loss:1.06478, train_acc:0.44950, val_loss=1.07412, val_acc=0.44092\n",
      "T:65, train_loss:1.06398, train_acc:0.45312, val_loss=1.07362, val_acc=0.43190\n",
      "T:66, train_loss:1.05835, train_acc:0.46649, val_loss=1.07489, val_acc=0.43169\n",
      "T:67, train_loss:1.05871, train_acc:0.46558, val_loss=1.07582, val_acc=0.42593\n",
      "T:68, train_loss:1.05795, train_acc:0.45950, val_loss=1.07533, val_acc=0.43126\n",
      "T:69, train_loss:1.05426, train_acc:0.47010, val_loss=1.07538, val_acc=0.42720\n",
      "T:70, train_loss:1.05710, train_acc:0.46197, val_loss=1.07457, val_acc=0.43080\n",
      "T:71, train_loss:1.05651, train_acc:0.46414, val_loss=1.07383, val_acc=0.43452\n",
      "T:72, train_loss:1.05398, train_acc:0.46649, val_loss=1.07301, val_acc=0.43838\n",
      "T:73, train_loss:1.06036, train_acc:0.45935, val_loss=1.07445, val_acc=0.43621\n",
      "T:74, train_loss:1.05927, train_acc:0.45658, val_loss=1.07203, val_acc=0.44025\n",
      "T:75, train_loss:1.06117, train_acc:0.45587, val_loss=1.07194, val_acc=0.43803\n",
      "T:76, train_loss:1.06717, train_acc:0.45216, val_loss=1.07102, val_acc=0.44009\n",
      "T:77, train_loss:1.06426, train_acc:0.45240, val_loss=1.06726, val_acc=0.44000\n",
      "T:78, train_loss:1.06481, train_acc:0.45210, val_loss=1.06132, val_acc=0.44898\n",
      "T:79, train_loss:1.06068, train_acc:0.46035, val_loss=1.05929, val_acc=0.45833\n",
      "T:80, train_loss:1.06166, train_acc:0.46194, val_loss=1.05693, val_acc=0.46099\n",
      "T:81, train_loss:1.05639, train_acc:0.46907, val_loss=1.05700, val_acc=0.45652\n",
      "T:82, train_loss:1.05411, train_acc:0.46860, val_loss=1.05949, val_acc=0.45679\n",
      "T:83, train_loss:1.05807, train_acc:0.45917, val_loss=1.05945, val_acc=0.45960\n",
      "T:84, train_loss:1.05660, train_acc:0.45799, val_loss=1.05434, val_acc=0.46512\n",
      "T:85, train_loss:1.05026, train_acc:0.46171, val_loss=1.05474, val_acc=0.46825\n",
      "T:86, train_loss:1.04685, train_acc:0.47007, val_loss=1.05534, val_acc=0.47154\n",
      "T:87, train_loss:1.04329, train_acc:0.47396, val_loss=1.05837, val_acc=0.46111\n",
      "T:88, train_loss:1.03885, train_acc:0.47643, val_loss=1.06105, val_acc=0.45869\n",
      "T:89, train_loss:1.02960, train_acc:0.49364, val_loss=1.06512, val_acc=0.46199\n",
      "T:90, train_loss:1.02884, train_acc:0.49040, val_loss=1.06711, val_acc=0.45345\n",
      "T:91, train_loss:1.02328, train_acc:0.49452, val_loss=1.06756, val_acc=0.45679\n",
      "T:92, train_loss:1.01866, train_acc:0.50041, val_loss=1.06686, val_acc=0.46349\n",
      "T:93, train_loss:1.02195, train_acc:0.49546, val_loss=1.06836, val_acc=0.45752\n",
      "T:94, train_loss:1.02635, train_acc:0.48904, val_loss=1.06476, val_acc=0.46801\n",
      "T:95, train_loss:1.02108, train_acc:0.49576, val_loss=1.06572, val_acc=0.46181\n",
      "T:96, train_loss:1.02397, train_acc:0.49552, val_loss=1.06592, val_acc=0.45878\n",
      "T:97, train_loss:1.01958, train_acc:0.49688, val_loss=1.06629, val_acc=0.46296\n",
      "T:98, train_loss:1.01747, train_acc:0.50477, val_loss=1.07392, val_acc=0.46360\n",
      "T:99, train_loss:1.01360, train_acc:0.50460, val_loss=1.07903, val_acc=0.44444\n",
      "T:100, train_loss:1.01463, train_acc:0.51208, val_loss=1.08179, val_acc=0.45267\n",
      "T:101, train_loss:1.01356, train_acc:0.51007, val_loss=1.07992, val_acc=0.44872\n",
      "T:102, train_loss:1.02126, train_acc:0.50094, val_loss=1.08388, val_acc=0.45778\n",
      "T:103, train_loss:1.01572, train_acc:0.50748, val_loss=1.07932, val_acc=0.48148\n",
      "T:104, train_loss:1.01504, train_acc:0.51296, val_loss=1.08593, val_acc=0.46860\n",
      "T:105, train_loss:1.02012, train_acc:0.51408, val_loss=1.09178, val_acc=0.45455\n",
      "T:106, train_loss:1.02582, train_acc:0.50778, val_loss=1.08680, val_acc=0.46032\n",
      "T:107, train_loss:1.03305, train_acc:0.50189, val_loss=1.08095, val_acc=0.46667\n",
      "T:108, train_loss:1.03114, train_acc:0.49918, val_loss=1.07840, val_acc=0.45614\n",
      "T:109, train_loss:1.03305, train_acc:0.50242, val_loss=1.07488, val_acc=0.46914\n",
      "T:110, train_loss:1.04147, train_acc:0.50049, val_loss=1.07179, val_acc=0.46405\n",
      "T:111, train_loss:1.03179, train_acc:0.50643, val_loss=1.06433, val_acc=0.47222\n",
      "T:112, train_loss:1.03404, train_acc:0.50579, val_loss=1.07460, val_acc=0.45926\n",
      "T:113, train_loss:1.03480, train_acc:0.50372, val_loss=1.06402, val_acc=0.46825\n",
      "T:114, train_loss:1.02868, train_acc:0.51041, val_loss=1.06135, val_acc=0.48718\n",
      "T:115, train_loss:1.01876, train_acc:0.50920, val_loss=1.06345, val_acc=0.50000\n",
      "T:116, train_loss:1.01027, train_acc:0.51756, val_loss=1.07434, val_acc=0.50505\n",
      "T:117, train_loss:1.02075, train_acc:0.50977, val_loss=1.08412, val_acc=0.51111\n",
      "T:118, train_loss:1.01306, train_acc:0.51727, val_loss=1.04842, val_acc=0.54321\n",
      "T:119, train_loss:1.01951, train_acc:0.51998, val_loss=1.05813, val_acc=0.52778\n",
      "T:120, train_loss:1.01567, train_acc:0.52015, val_loss=1.03891, val_acc=0.53968\n",
      "T:121, train_loss:1.01480, train_acc:0.52004, val_loss=1.02955, val_acc=0.57407\n",
      "T:122, train_loss:1.01856, train_acc:0.51865, val_loss=1.03980, val_acc=0.57778\n",
      "T:123, train_loss:1.01377, train_acc:0.52551, val_loss=1.01668, val_acc=0.55556\n",
      "T:124, train_loss:1.00614, train_acc:0.52586, val_loss=1.06988, val_acc=0.48148\n",
      "T:125, train_loss:1.00397, train_acc:0.53099, val_loss=1.03464, val_acc=0.44444\n",
      "T:126, train_loss:1.00948, train_acc:0.52096, val_loss=1.08599, val_acc=0.33333\n",
      "0.4601006560437948\n",
      "accuracy on testing data is: 0.4453125\n"
     ]
    }
   ],
   "source": [
    "def run_flat_cont(filename, dir_prefix=\"../\", lr=0.00001, exp_num=0, **kwargs):\n",
    "    \"\"\"\n",
    "    Training a Simple ANN model with embedding using continuous evaluation. The model is then saved into pickle.\n",
    "    :param filename: the name of the file with the input data\n",
    "    :param dir_prefix: directory prefix for model saving\n",
    "    :param lr: a learning rate for training\n",
    "    :param exp_num: experiment number\n",
    "    :param kwargs: additional parameters for the model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    epochs = [30]  # number of initial epochs\n",
    "    test_acc = []\n",
    "    val_acc = []\n",
    "    n_all_teams = 0\n",
    "    for data in data_list:\n",
    "        n_all_teams += data.n_teams\n",
    "    model = FlatModel(n_all_teams, **kwargs)\n",
    "\n",
    "    for i, data in enumerate(data_list):\n",
    "        print(\"Flat model, data {}\", i)\n",
    "        continuous_evaluation(data, model, epochs[0],lr=lr, batch_size=9)\n",
    "        test_cont(data, model, data.data_test, \"test\")\n",
    "        print(\"accuracy on testing data is: {}\".format(data.test_accuracy))\n",
    "        rps = get_rps(data, model, data.data_test)\n",
    "        print(\"rps is below\")\n",
    "        #file = outfile.format(pickle_dir.format(dir_prefix), i, exp_num, \"pickle\")\n",
    "        #data_to_save = {\"data\": data, \"model\": model, \"epochs\": epochs}\n",
    "        #save_to_pickle(file, data_to_save)\n",
    "        test_acc.append(data.test_accuracy)\n",
    "        val_acc.append(data.val_acc)\n",
    "\n",
    "    test_accuracy = sum(test_acc)/len(test_acc)\n",
    "    val_accuracy = sum(val_acc)/len(val_acc)\n",
    "    #file = outfile.format(pickle_dir.format(dir_prefix), \"all\", exp_num, \"pickle\")\n",
    "    #data_to_save = {\"test_acc\":test_acc, \"val_acc\":val_acc}\n",
    "    #save_to_pickle(file, data_to_save)\n",
    "    return test_accuracy, val_accuracy,model, dataset\n",
    "\n",
    "test_acc, val_acc, model,dataset = run_flat_cont(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0565eff-c587-445d-8931-a2ebc934d55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for data in data_list:\n",
    "    y_pred, y_true, prob = get_predictions(data, model, data.data_test)\n",
    "    y_pred, y_true = y_pred.numpy().astype('int'), y_true.numpy().astype('int')        \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[2, 1, 0])  # Assuming labels are 2 for \"W\", 1 for \"D\", and 2 for \"L\"\n",
    "\n",
    "    # Visualize the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"W\", \"D\", \"L\"])\n",
    "    disp.plot(cmap='Blues')\n",
    "    fig1 = plt.gcf()\n",
    "    plt.show()\n",
    "    fig1.savefig('cm_ann.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7defe-a8c0-4c68-9a4b-119426698df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
